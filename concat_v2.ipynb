{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c29815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "                            roc_auc_score, confusion_matrix, classification_report, \\\n",
    "                            matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82d299d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완벽한 실험 재현성을 위한 랜덤제어\n",
    "random_seed = 28\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8725d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d07c2a",
   "metadata": {},
   "source": [
    "# Vision Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcfecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27dbae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"C:/Users/ANDlab3/Desktop/paper/fashion-dataset/data/\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(image_path, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val','test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val','test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "class_num = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932fbb2",
   "metadata": {},
   "source": [
    "# Vision Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d6e2bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "#Changing the number of outputs in the last layer to the number of different item types\n",
    "model_ft.fc = nn.Linear(num_ftrs, 500)\n",
    "pre_model= model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ab0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_classifier(nn.Module):\n",
    "    def __init__(self, pre_model):\n",
    "        super(resnet_classifier, self).__init__()\n",
    "    \n",
    "        D_in, H, D_out = 1000, 500, 37\n",
    "        self.resnet50 = pre_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        outputs = self.resnet50(image)\n",
    "        \n",
    "        fc = self.classifier(outputs)\n",
    "        \n",
    "        return  outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d0e6401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet_classifier(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_module = resnet_classifier(pre_model)\n",
    "vision_module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06fd690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SAVE_PATH = \"C:/Users/ANDlab3/Desktop/paper/fashion-dataset/model/\"\n",
    "vision_module.load_state_dict(torch.load(IMG_SAVE_PATH+'model_fine_tuned_v2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eaeb805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet_classifier(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61dcb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 resnet50.conv1.weight\n",
      "1 resnet50.bn1.weight\n",
      "2 resnet50.bn1.bias\n",
      "3 resnet50.layer1.0.conv1.weight\n",
      "4 resnet50.layer1.0.bn1.weight\n",
      "5 resnet50.layer1.0.bn1.bias\n",
      "6 resnet50.layer1.0.conv2.weight\n",
      "7 resnet50.layer1.0.bn2.weight\n",
      "8 resnet50.layer1.0.bn2.bias\n",
      "9 resnet50.layer1.0.conv3.weight\n",
      "10 resnet50.layer1.0.bn3.weight\n",
      "11 resnet50.layer1.0.bn3.bias\n",
      "12 resnet50.layer1.0.downsample.0.weight\n",
      "13 resnet50.layer1.0.downsample.1.weight\n",
      "14 resnet50.layer1.0.downsample.1.bias\n",
      "15 resnet50.layer1.1.conv1.weight\n",
      "16 resnet50.layer1.1.bn1.weight\n",
      "17 resnet50.layer1.1.bn1.bias\n",
      "18 resnet50.layer1.1.conv2.weight\n",
      "19 resnet50.layer1.1.bn2.weight\n",
      "20 resnet50.layer1.1.bn2.bias\n",
      "21 resnet50.layer1.1.conv3.weight\n",
      "22 resnet50.layer1.1.bn3.weight\n",
      "23 resnet50.layer1.1.bn3.bias\n",
      "24 resnet50.layer1.2.conv1.weight\n",
      "25 resnet50.layer1.2.bn1.weight\n",
      "26 resnet50.layer1.2.bn1.bias\n",
      "27 resnet50.layer1.2.conv2.weight\n",
      "28 resnet50.layer1.2.bn2.weight\n",
      "29 resnet50.layer1.2.bn2.bias\n",
      "30 resnet50.layer1.2.conv3.weight\n",
      "31 resnet50.layer1.2.bn3.weight\n",
      "32 resnet50.layer1.2.bn3.bias\n",
      "33 resnet50.layer2.0.conv1.weight\n",
      "34 resnet50.layer2.0.bn1.weight\n",
      "35 resnet50.layer2.0.bn1.bias\n",
      "36 resnet50.layer2.0.conv2.weight\n",
      "37 resnet50.layer2.0.bn2.weight\n",
      "38 resnet50.layer2.0.bn2.bias\n",
      "39 resnet50.layer2.0.conv3.weight\n",
      "40 resnet50.layer2.0.bn3.weight\n",
      "41 resnet50.layer2.0.bn3.bias\n",
      "42 resnet50.layer2.0.downsample.0.weight\n",
      "43 resnet50.layer2.0.downsample.1.weight\n",
      "44 resnet50.layer2.0.downsample.1.bias\n",
      "45 resnet50.layer2.1.conv1.weight\n",
      "46 resnet50.layer2.1.bn1.weight\n",
      "47 resnet50.layer2.1.bn1.bias\n",
      "48 resnet50.layer2.1.conv2.weight\n",
      "49 resnet50.layer2.1.bn2.weight\n",
      "50 resnet50.layer2.1.bn2.bias\n",
      "51 resnet50.layer2.1.conv3.weight\n",
      "52 resnet50.layer2.1.bn3.weight\n",
      "53 resnet50.layer2.1.bn3.bias\n",
      "54 resnet50.layer2.2.conv1.weight\n",
      "55 resnet50.layer2.2.bn1.weight\n",
      "56 resnet50.layer2.2.bn1.bias\n",
      "57 resnet50.layer2.2.conv2.weight\n",
      "58 resnet50.layer2.2.bn2.weight\n",
      "59 resnet50.layer2.2.bn2.bias\n",
      "60 resnet50.layer2.2.conv3.weight\n",
      "61 resnet50.layer2.2.bn3.weight\n",
      "62 resnet50.layer2.2.bn3.bias\n",
      "63 resnet50.layer2.3.conv1.weight\n",
      "64 resnet50.layer2.3.bn1.weight\n",
      "65 resnet50.layer2.3.bn1.bias\n",
      "66 resnet50.layer2.3.conv2.weight\n",
      "67 resnet50.layer2.3.bn2.weight\n",
      "68 resnet50.layer2.3.bn2.bias\n",
      "69 resnet50.layer2.3.conv3.weight\n",
      "70 resnet50.layer2.3.bn3.weight\n",
      "71 resnet50.layer2.3.bn3.bias\n",
      "72 resnet50.layer3.0.conv1.weight\n",
      "73 resnet50.layer3.0.bn1.weight\n",
      "74 resnet50.layer3.0.bn1.bias\n",
      "75 resnet50.layer3.0.conv2.weight\n",
      "76 resnet50.layer3.0.bn2.weight\n",
      "77 resnet50.layer3.0.bn2.bias\n",
      "78 resnet50.layer3.0.conv3.weight\n",
      "79 resnet50.layer3.0.bn3.weight\n",
      "80 resnet50.layer3.0.bn3.bias\n",
      "81 resnet50.layer3.0.downsample.0.weight\n",
      "82 resnet50.layer3.0.downsample.1.weight\n",
      "83 resnet50.layer3.0.downsample.1.bias\n",
      "84 resnet50.layer3.1.conv1.weight\n",
      "85 resnet50.layer3.1.bn1.weight\n",
      "86 resnet50.layer3.1.bn1.bias\n",
      "87 resnet50.layer3.1.conv2.weight\n",
      "88 resnet50.layer3.1.bn2.weight\n",
      "89 resnet50.layer3.1.bn2.bias\n",
      "90 resnet50.layer3.1.conv3.weight\n",
      "91 resnet50.layer3.1.bn3.weight\n",
      "92 resnet50.layer3.1.bn3.bias\n",
      "93 resnet50.layer3.2.conv1.weight\n",
      "94 resnet50.layer3.2.bn1.weight\n",
      "95 resnet50.layer3.2.bn1.bias\n",
      "96 resnet50.layer3.2.conv2.weight\n",
      "97 resnet50.layer3.2.bn2.weight\n",
      "98 resnet50.layer3.2.bn2.bias\n",
      "99 resnet50.layer3.2.conv3.weight\n",
      "100 resnet50.layer3.2.bn3.weight\n",
      "101 resnet50.layer3.2.bn3.bias\n",
      "102 resnet50.layer3.3.conv1.weight\n",
      "103 resnet50.layer3.3.bn1.weight\n",
      "104 resnet50.layer3.3.bn1.bias\n",
      "105 resnet50.layer3.3.conv2.weight\n",
      "106 resnet50.layer3.3.bn2.weight\n",
      "107 resnet50.layer3.3.bn2.bias\n",
      "108 resnet50.layer3.3.conv3.weight\n",
      "109 resnet50.layer3.3.bn3.weight\n",
      "110 resnet50.layer3.3.bn3.bias\n",
      "111 resnet50.layer3.4.conv1.weight\n",
      "112 resnet50.layer3.4.bn1.weight\n",
      "113 resnet50.layer3.4.bn1.bias\n",
      "114 resnet50.layer3.4.conv2.weight\n",
      "115 resnet50.layer3.4.bn2.weight\n",
      "116 resnet50.layer3.4.bn2.bias\n",
      "117 resnet50.layer3.4.conv3.weight\n",
      "118 resnet50.layer3.4.bn3.weight\n",
      "119 resnet50.layer3.4.bn3.bias\n",
      "120 resnet50.layer3.5.conv1.weight\n",
      "121 resnet50.layer3.5.bn1.weight\n",
      "122 resnet50.layer3.5.bn1.bias\n",
      "123 resnet50.layer3.5.conv2.weight\n",
      "124 resnet50.layer3.5.bn2.weight\n",
      "125 resnet50.layer3.5.bn2.bias\n",
      "126 resnet50.layer3.5.conv3.weight\n",
      "127 resnet50.layer3.5.bn3.weight\n",
      "128 resnet50.layer3.5.bn3.bias\n",
      "129 resnet50.layer4.0.conv1.weight\n",
      "130 resnet50.layer4.0.bn1.weight\n",
      "131 resnet50.layer4.0.bn1.bias\n",
      "132 resnet50.layer4.0.conv2.weight\n",
      "133 resnet50.layer4.0.bn2.weight\n",
      "134 resnet50.layer4.0.bn2.bias\n",
      "135 resnet50.layer4.0.conv3.weight\n",
      "136 resnet50.layer4.0.bn3.weight\n",
      "137 resnet50.layer4.0.bn3.bias\n",
      "138 resnet50.layer4.0.downsample.0.weight\n",
      "139 resnet50.layer4.0.downsample.1.weight\n",
      "140 resnet50.layer4.0.downsample.1.bias\n",
      "141 resnet50.layer4.1.conv1.weight\n",
      "142 resnet50.layer4.1.bn1.weight\n",
      "143 resnet50.layer4.1.bn1.bias\n",
      "144 resnet50.layer4.1.conv2.weight\n",
      "145 resnet50.layer4.1.bn2.weight\n",
      "146 resnet50.layer4.1.bn2.bias\n",
      "147 resnet50.layer4.1.conv3.weight\n",
      "148 resnet50.layer4.1.bn3.weight\n",
      "149 resnet50.layer4.1.bn3.bias\n",
      "150 resnet50.layer4.2.conv1.weight\n",
      "151 resnet50.layer4.2.bn1.weight\n",
      "152 resnet50.layer4.2.bn1.bias\n",
      "153 resnet50.layer4.2.conv2.weight\n",
      "154 resnet50.layer4.2.bn2.weight\n",
      "155 resnet50.layer4.2.bn2.bias\n",
      "156 resnet50.layer4.2.conv3.weight\n",
      "157 resnet50.layer4.2.bn3.weight\n",
      "158 resnet50.layer4.2.bn3.bias\n",
      "159 resnet50.fc.weight\n",
      "160 resnet50.fc.bias\n",
      "161 classifier.2.weight\n",
      "162 classifier.2.bias\n"
     ]
    }
   ],
   "source": [
    "# 파라메타 번호 확인 하기\n",
    "i = 0\n",
    "for name, param in vision_module.named_parameters():\n",
    "    \n",
    "    print(i,name)\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1839cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(vision_module.named_parameters()):\n",
    "    \n",
    "    param.requires_grad = False\n",
    "    if i == 160:\n",
    "        print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b961279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('resnet50.conv1.weight', Parameter containing:\n",
      "tensor([[[[ 2.9832e-02,  2.7486e-02, -5.4940e-04,  ..., -1.5218e-02,\n",
      "           -1.4472e-02, -4.5599e-02],\n",
      "          [ 1.7806e-02,  1.4144e-02,  2.7383e-02,  ...,  2.5815e-02,\n",
      "            3.9620e-03, -1.4788e-02],\n",
      "          [ 3.1399e-02,  2.4234e-02,  2.0323e-02,  ...,  1.1810e-01,\n",
      "            8.3817e-02,  7.4766e-02],\n",
      "          ...,\n",
      "          [ 8.8523e-03,  3.3135e-02, -2.9771e-03,  ..., -1.2287e-01,\n",
      "           -6.9704e-02,  1.5388e-02],\n",
      "          [ 2.0160e-02,  5.8223e-02,  7.5046e-02,  ...,  3.1977e-02,\n",
      "           -2.5193e-02, -7.6963e-03],\n",
      "          [-6.8655e-02, -2.2381e-02, -3.6866e-03,  ...,  5.2400e-02,\n",
      "            4.0082e-02,  1.5968e-02]],\n",
      "\n",
      "         [[ 2.5577e-03,  2.6901e-02,  3.7032e-02,  ...,  8.2444e-02,\n",
      "            7.5451e-02,  1.6257e-02],\n",
      "          [ 1.6055e-02,  3.5968e-02,  8.7621e-02,  ...,  1.9196e-01,\n",
      "            1.7871e-01,  1.4971e-01],\n",
      "          [-2.9695e-02, -6.6044e-02, -7.6467e-02,  ...,  1.4619e-01,\n",
      "            1.9754e-01,  2.0638e-01],\n",
      "          ...,\n",
      "          [ 3.8649e-02,  1.6417e-02, -7.9462e-02,  ..., -3.6901e-01,\n",
      "           -2.8917e-01, -1.2853e-01],\n",
      "          [ 1.0221e-01,  1.4520e-01,  1.5985e-01,  ...,  4.3640e-03,\n",
      "           -1.1093e-01, -1.2078e-01],\n",
      "          [ 5.5359e-03,  7.9985e-02,  1.4403e-01,  ...,  1.9619e-01,\n",
      "            1.2703e-01,  3.2209e-02]],\n",
      "\n",
      "         [[-1.4120e-03,  3.1868e-03,  1.3561e-02,  ...,  4.3952e-02,\n",
      "            4.9939e-02,  1.5254e-02],\n",
      "          [ 1.1132e-02,  1.8388e-02,  6.5394e-02,  ...,  1.5035e-01,\n",
      "            1.4673e-01,  1.3538e-01],\n",
      "          [-4.8756e-02, -9.3940e-02, -8.9665e-02,  ...,  1.2344e-01,\n",
      "            1.6278e-01,  1.7212e-01],\n",
      "          ...,\n",
      "          [ 3.3724e-02,  1.4032e-02, -7.0524e-02,  ..., -3.1058e-01,\n",
      "           -2.4796e-01, -1.1975e-01],\n",
      "          [ 9.0138e-02,  1.2291e-01,  1.4215e-01,  ..., -6.0041e-04,\n",
      "           -1.1674e-01, -1.2038e-01],\n",
      "          [ 8.0072e-03,  7.6705e-02,  1.3271e-01,  ...,  2.0332e-01,\n",
      "            1.2784e-01,  3.1467e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3271e-01,  7.4851e-02,  9.1012e-02,  ...,  6.3618e-02,\n",
      "            8.5126e-02,  9.5804e-02],\n",
      "          [ 8.9751e-02,  2.0948e-02,  3.0564e-02,  ..., -6.1650e-02,\n",
      "           -3.3364e-02, -1.3727e-02],\n",
      "          [ 7.7827e-02,  8.2469e-03, -4.1489e-03,  ..., -1.4861e-01,\n",
      "           -1.0536e-01, -5.3553e-02],\n",
      "          ...,\n",
      "          [ 2.4635e-02, -8.5861e-02, -1.3572e-01,  ..., -2.5531e-01,\n",
      "           -2.3069e-01, -2.0212e-01],\n",
      "          [ 7.2842e-02, -3.8811e-02, -7.6123e-02,  ..., -2.4902e-01,\n",
      "           -1.9295e-01, -1.5888e-01],\n",
      "          [ 7.7172e-02, -1.8420e-02, -7.2531e-02,  ..., -1.9070e-01,\n",
      "           -1.4938e-01, -9.1780e-02]],\n",
      "\n",
      "         [[-5.8947e-02, -6.1185e-02, -5.9291e-02,  ..., -5.4714e-04,\n",
      "           -3.9314e-02, -5.2495e-02],\n",
      "          [-4.8564e-02, -4.1440e-02, -3.4921e-03,  ...,  5.6664e-02,\n",
      "            3.0921e-02, -7.0000e-03],\n",
      "          [-7.6646e-02, -3.4532e-02,  3.5828e-02,  ...,  1.9704e-01,\n",
      "            1.6581e-01,  1.0396e-01],\n",
      "          ...,\n",
      "          [-1.9435e-02,  5.6184e-02,  1.7815e-01,  ...,  4.9767e-01,\n",
      "            4.3149e-01,  2.9840e-01],\n",
      "          [-3.0291e-02,  2.0037e-02,  1.4077e-01,  ...,  3.9018e-01,\n",
      "            3.6356e-01,  2.4377e-01],\n",
      "          [-6.9369e-02, -3.0004e-02,  3.7036e-02,  ...,  2.2685e-01,\n",
      "            2.1125e-01,  1.6363e-01]],\n",
      "\n",
      "         [[ 4.5995e-02,  2.6833e-02,  9.7864e-04,  ...,  3.7596e-02,\n",
      "            3.9249e-02,  4.7017e-02],\n",
      "          [ 3.2158e-02,  1.1715e-02, -1.6004e-02,  ..., -1.6968e-02,\n",
      "           -9.2334e-03,  1.1616e-02],\n",
      "          [ 1.2987e-02, -1.4293e-02, -3.4818e-02,  ..., -1.0427e-01,\n",
      "           -9.0563e-02, -3.0713e-02],\n",
      "          ...,\n",
      "          [ 2.9983e-02, -1.8384e-02, -8.2697e-02,  ..., -1.6377e-01,\n",
      "           -1.3468e-01, -2.8409e-02],\n",
      "          [ 4.3048e-02, -2.0435e-02, -6.1671e-02,  ..., -1.4584e-01,\n",
      "           -9.9651e-02, -1.4591e-02],\n",
      "          [ 5.7596e-02,  1.4875e-02, -3.2632e-02,  ..., -5.7782e-02,\n",
      "           -3.9640e-02,  3.6577e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0623e-03,  1.1488e-02, -3.4543e-04,  ..., -2.9513e-02,\n",
      "           -1.5233e-02, -1.8997e-02],\n",
      "          [ 2.4412e-02,  3.8699e-02,  2.8377e-02,  ...,  5.2280e-03,\n",
      "            9.6643e-03, -1.5581e-02],\n",
      "          [ 1.8175e-02,  3.9383e-02,  3.2510e-02,  ...,  3.1704e-02,\n",
      "            1.9822e-02,  1.0895e-02],\n",
      "          ...,\n",
      "          [-1.0035e-04,  1.8798e-02,  7.1117e-03,  ...,  4.7639e-02,\n",
      "            6.9934e-02,  1.0210e-01],\n",
      "          [-1.7083e-02,  1.5641e-02,  9.8230e-03,  ...,  1.5137e-02,\n",
      "            3.9346e-02,  1.0326e-01],\n",
      "          [-2.7094e-02,  7.4912e-04,  2.9070e-03,  ...,  2.6333e-03,\n",
      "            4.3820e-02,  1.1574e-01]],\n",
      "\n",
      "         [[ 9.3606e-04, -8.1584e-03, -1.1100e-02,  ...,  1.9935e-02,\n",
      "            5.8835e-02,  6.2273e-02],\n",
      "          [ 9.9546e-03,  8.0890e-04, -9.2377e-03,  ...,  3.0137e-02,\n",
      "            6.6059e-02,  4.0550e-02],\n",
      "          [-8.4490e-03, -1.5853e-02, -3.1655e-02,  ...,  4.6624e-02,\n",
      "            6.2607e-02,  3.9374e-02],\n",
      "          ...,\n",
      "          [-3.1015e-02, -5.5424e-02, -1.0006e-01,  ..., -5.6845e-02,\n",
      "           -1.3197e-02,  1.6868e-02],\n",
      "          [-1.5185e-02, -1.6850e-02, -5.8745e-02,  ..., -9.7913e-02,\n",
      "           -6.6496e-02, -2.8630e-03],\n",
      "          [ 7.4554e-03,  7.2138e-03, -1.8749e-02,  ..., -7.0938e-02,\n",
      "           -4.2350e-02,  7.0248e-03]],\n",
      "\n",
      "         [[ 3.1754e-03, -4.8923e-02, -3.7162e-02,  ...,  3.2832e-02,\n",
      "            9.3294e-02,  7.1710e-02],\n",
      "          [-2.7841e-02, -8.5001e-02, -8.0196e-02,  ..., -1.1503e-02,\n",
      "            3.1507e-02, -1.7723e-02],\n",
      "          [-1.2005e-02, -7.3486e-02, -8.7667e-02,  ..., -4.2959e-03,\n",
      "            6.4790e-03, -3.6188e-02],\n",
      "          ...,\n",
      "          [-1.8390e-02, -8.1327e-02, -1.1947e-01,  ..., -1.0819e-01,\n",
      "           -9.8030e-02, -1.0934e-01],\n",
      "          [ 4.7277e-03, -3.0742e-02, -6.8087e-02,  ..., -1.2710e-01,\n",
      "           -1.4065e-01, -1.2190e-01],\n",
      "          [ 3.9688e-02, -1.3090e-03, -2.5759e-02,  ..., -9.7919e-02,\n",
      "           -1.1318e-01, -1.0320e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6070e-02,  2.2761e-02,  2.7596e-02,  ..., -7.2084e-03,\n",
      "            4.3820e-02, -8.8459e-03],\n",
      "          [-2.8920e-02,  4.6527e-02,  4.5462e-02,  ..., -7.0489e-02,\n",
      "            8.7716e-02, -3.0074e-02],\n",
      "          [-6.7906e-02,  8.4036e-02,  4.4417e-02,  ..., -1.0491e-01,\n",
      "            1.6031e-01, -2.5267e-02],\n",
      "          ...,\n",
      "          [ 3.8494e-03,  1.2276e-01, -6.0471e-02,  ...,  6.6186e-02,\n",
      "            1.8485e-01, -1.4808e-02],\n",
      "          [ 1.0694e-02,  6.1068e-02, -7.1778e-02,  ...,  5.4177e-02,\n",
      "            1.1649e-01, -2.3087e-02],\n",
      "          [ 2.8992e-02,  9.2142e-03, -6.7087e-02,  ...,  5.9826e-02,\n",
      "            7.5215e-02,  5.9201e-03]],\n",
      "\n",
      "         [[ 2.1897e-02,  6.1949e-02,  1.9688e-02,  ..., -6.0848e-02,\n",
      "            5.2893e-02,  4.3613e-02],\n",
      "          [ 4.4952e-03,  1.2972e-01,  3.3943e-02,  ..., -1.5776e-01,\n",
      "            1.4379e-01,  6.5267e-02],\n",
      "          [-3.1410e-03,  2.0723e-01,  1.2444e-02,  ..., -2.0151e-01,\n",
      "            2.6172e-01,  8.7624e-02],\n",
      "          ...,\n",
      "          [ 4.8845e-02,  1.8702e-01, -1.5732e-01,  ...,  3.7393e-02,\n",
      "            3.0313e-01,  6.3754e-02],\n",
      "          [ 3.2461e-02,  8.9434e-02, -1.5658e-01,  ...,  5.0389e-02,\n",
      "            1.7973e-01, -8.4554e-03],\n",
      "          [ 3.1252e-02,  3.1645e-02, -1.1128e-01,  ...,  7.3560e-02,\n",
      "            9.8823e-02, -6.2564e-03]],\n",
      "\n",
      "         [[ 1.7156e-02,  4.3317e-02,  3.9017e-02,  ..., -2.9908e-02,\n",
      "            1.6836e-02,  7.5857e-03],\n",
      "          [-2.1170e-02,  8.3197e-02,  8.1931e-02,  ..., -5.9689e-02,\n",
      "            7.6334e-02, -2.6882e-03],\n",
      "          [-4.9813e-02,  1.1874e-01,  7.7675e-02,  ..., -8.6904e-02,\n",
      "            1.3565e-01, -1.3008e-02],\n",
      "          ...,\n",
      "          [-2.2131e-03,  1.1224e-01, -5.7788e-02,  ...,  3.8179e-02,\n",
      "            1.4170e-01, -1.8931e-02],\n",
      "          [-2.3793e-03,  6.0094e-02, -5.9870e-02,  ...,  3.2165e-02,\n",
      "            8.4279e-02, -4.3699e-02],\n",
      "          [ 1.5113e-02,  3.2180e-02, -4.3053e-02,  ...,  4.1944e-02,\n",
      "            4.4832e-02, -2.9555e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8371e-02,  2.3111e-02,  2.7255e-02,  ..., -7.9225e-02,\n",
      "           -3.9082e-02, -2.1738e-03],\n",
      "          [ 6.2171e-02,  4.0080e-02,  2.8668e-02,  ..., -1.8162e-01,\n",
      "           -1.2781e-01, -4.3833e-02],\n",
      "          [ 8.9873e-02,  5.9355e-02,  3.5261e-02,  ..., -3.0577e-01,\n",
      "           -1.6353e-01, -3.4066e-02],\n",
      "          ...,\n",
      "          [ 2.1928e-03, -6.8306e-02, -2.2451e-01,  ..., -3.7706e-01,\n",
      "           -1.8694e-01,  4.9783e-02],\n",
      "          [ 2.1930e-02, -5.1446e-02, -1.7303e-01,  ..., -3.1269e-01,\n",
      "           -4.1651e-02,  1.0837e-01],\n",
      "          [ 3.3756e-02, -3.2420e-02, -1.3619e-01,  ..., -2.1012e-01,\n",
      "            3.3837e-02,  1.4725e-01]],\n",
      "\n",
      "         [[ 3.8938e-03,  3.4659e-03,  2.0930e-02,  ..., -5.7709e-03,\n",
      "            9.1954e-05,  1.3016e-02],\n",
      "          [ 5.1793e-02,  2.0787e-02,  3.8423e-02,  ..., -1.0601e-02,\n",
      "           -5.9145e-03,  1.0909e-02],\n",
      "          [ 4.5666e-02,  1.3958e-02,  4.8802e-02,  ..., -7.3842e-02,\n",
      "            4.8122e-04,  3.1996e-02],\n",
      "          ...,\n",
      "          [-3.7414e-03, -7.8300e-03, -5.9151e-02,  ..., -7.1368e-02,\n",
      "           -4.0398e-02,  6.8512e-02],\n",
      "          [ 3.1019e-02,  1.2100e-02, -1.1089e-02,  ..., -8.3419e-02,\n",
      "            1.7786e-02,  5.8466e-02],\n",
      "          [ 5.3996e-02,  3.4123e-02,  1.5589e-02,  ..., -4.0828e-02,\n",
      "            4.5201e-02,  5.8432e-02]],\n",
      "\n",
      "         [[-4.5272e-02, -4.1040e-02, -2.9606e-02,  ..., -8.5395e-03,\n",
      "           -2.3394e-03, -1.4117e-02],\n",
      "          [-5.3652e-03, -2.6565e-02, -1.1860e-03,  ...,  2.4939e-02,\n",
      "            1.7292e-02,  7.2781e-04],\n",
      "          [-2.1058e-02, -4.5718e-02,  1.3222e-02,  ...,  1.5375e-02,\n",
      "            3.9057e-02, -3.5208e-03],\n",
      "          ...,\n",
      "          [-2.2208e-02, -2.3465e-03,  1.0345e-02,  ...,  3.9315e-02,\n",
      "           -1.3557e-02, -2.1662e-02],\n",
      "          [ 9.7192e-03,  2.1227e-02,  5.4671e-02,  ...,  2.5527e-02,\n",
      "            2.3256e-02, -3.0518e-02],\n",
      "          [ 2.3091e-02,  3.4216e-02,  6.2642e-02,  ...,  1.8940e-02,\n",
      "            2.0503e-02, -3.0864e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9478e-02, -3.2873e-02,  5.9774e-02,  ..., -4.6018e-02,\n",
      "            1.8675e-02,  1.2231e-02],\n",
      "          [-4.3079e-02,  5.6632e-02, -2.1258e-02,  ...,  3.0026e-02,\n",
      "           -9.9150e-04,  7.7578e-03],\n",
      "          [ 4.8381e-02, -4.3220e-02, -2.9631e-02,  ..., -2.0782e-01,\n",
      "            1.6216e-02,  5.3352e-02],\n",
      "          ...,\n",
      "          [-4.3521e-02,  7.8935e-02,  1.0564e-01,  ...,  5.3064e-01,\n",
      "           -4.1808e-02, -4.7158e-02],\n",
      "          [-2.1037e-02,  9.5506e-02, -2.1430e-01,  ...,  2.4240e-01,\n",
      "           -2.6944e-01,  1.2488e-01],\n",
      "          [-2.4825e-02, -2.8892e-03, -8.5831e-02,  ..., -5.1214e-02,\n",
      "            2.3550e-02, -3.4383e-02]],\n",
      "\n",
      "         [[ 2.5060e-02, -3.3351e-02,  4.7969e-02,  ..., -3.8486e-02,\n",
      "            2.5506e-02, -1.2564e-02],\n",
      "          [-3.8157e-02,  7.3537e-02, -5.8115e-03,  ...,  3.5514e-02,\n",
      "            9.0174e-03, -2.2288e-03],\n",
      "          [ 3.8378e-02, -5.3688e-02, -5.4205e-04,  ..., -2.5824e-01,\n",
      "            5.6706e-02,  3.1391e-02],\n",
      "          ...,\n",
      "          [-3.1422e-02,  1.3460e-01,  1.2487e-01,  ...,  6.6170e-01,\n",
      "           -2.9088e-02, -1.3989e-01],\n",
      "          [-2.2524e-02,  1.2714e-01, -2.5744e-01,  ...,  3.3856e-01,\n",
      "           -3.4760e-01,  6.3871e-02],\n",
      "          [-1.2893e-03,  2.5026e-02, -8.5834e-02,  ..., -6.6333e-02,\n",
      "           -8.0265e-03, -4.1694e-02]],\n",
      "\n",
      "         [[ 1.8265e-02, -3.1175e-02,  2.5749e-02,  ..., -4.5550e-02,\n",
      "            2.1465e-02, -5.8320e-03],\n",
      "          [-2.6700e-02,  8.5125e-02, -1.5873e-02,  ...,  5.0798e-02,\n",
      "           -3.6249e-03, -1.5388e-02],\n",
      "          [ 6.6158e-02, -3.3813e-02, -1.1655e-01,  ..., -1.3073e-01,\n",
      "            7.7335e-03,  9.6899e-03],\n",
      "          ...,\n",
      "          [-6.1366e-03,  1.7147e-02,  1.5110e-01,  ...,  4.7100e-01,\n",
      "           -1.7864e-01, -3.9830e-02],\n",
      "          [-4.3827e-02,  4.5814e-02, -1.2647e-01,  ...,  1.1271e-01,\n",
      "           -2.9888e-01,  1.4575e-01],\n",
      "          [ 1.0878e-02,  2.3981e-02, -8.9030e-03,  ..., -1.0612e-01,\n",
      "            4.8510e-02, -2.1200e-02]]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "for p in vision_module.named_parameters():\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cfa54",
   "metadata": {},
   "source": [
    "# NLP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f89915",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_train_path = \"C:/Users/ANDlab3/Desktop/VisionAndNLP/data/train.csv\"\n",
    "nlp_val_path = \"C:/Users/ANDlab3/Desktop/VisionAndNLP/data/val.csv\"\n",
    "nlp_test_path = \"C:/Users/ANDlab3/Desktop/VisionAndNLP/data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7847158",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_train_data = pd.read_csv(nlp_train_path)\n",
    "nlp_val_data = pd.read_csv(nlp_val_path)\n",
    "nlp_test_data = pd.read_csv(nlp_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21ece44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = nlp_train_data['productDisplayName']\n",
    "y_train = nlp_train_data['label']\n",
    "\n",
    "X_val = nlp_val_data['productDisplayName']\n",
    "y_val = nlp_val_data['label']\n",
    "\n",
    "X_test = nlp_test_data['productDisplayName']\n",
    "y_test = nlp_test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b497a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebdc1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8490b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANDlab3\\anaconda3\\envs\\GAN\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 30\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
    "test_inputs, test_masks = preprocessing_for_bert(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88eaaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "test_labels = torch.tensor(y_test)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7f3e5",
   "metadata": {},
   "source": [
    "# NLP Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13fb39d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 500, 37\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.dense = nn.Sequential(\n",
    "                nn.Linear(D_in, H),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "#         # Freeze the BERT model\n",
    "#         if freeze_bert:\n",
    "#             for param in self.bert.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        \n",
    "        dense = self.dense(last_hidden_state_cls)\n",
    "        logits = self.classifier(dense)\n",
    "\n",
    "        return dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac28daa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_module = BertClassifier()\n",
    "NLP_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02eb8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_SAVE_PATH = \"C:/Users/ANDlab3/Desktop/NLP/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "205d23f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_module= NLP_module.to(device) # 모델 선언\n",
    "NLP_module.load_state_dict(torch.load(NLP_SAVE_PATH+'bert_fine_tuned_v2.pt')) # 모델 파라메타 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6de54f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 파라메타 번호 확인 하기\n",
    "# i = 0\n",
    "# for name, param in NLP_module.named_parameters():\n",
    "    \n",
    "#     print(i,name)\n",
    "#     i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de3eb82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (name, param) in enumerate(NLP_module.named_parameters()):\n",
    "    \n",
    "#     param.requires_grad = False\n",
    "#     if i == 200:\n",
    "#         print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a0e85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in NLP_module.named_parameters():\n",
    "#     print(p)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ba6e71",
   "metadata": {},
   "source": [
    "# LanguageAndVisionConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35aa3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageAndVisionConcat(nn.Module):    \n",
    "    def __init__(\n",
    "        self,\n",
    "        nlp_module,\n",
    "        vision_module,\n",
    "        num_classes,\n",
    "        language_feature_dim,\n",
    "        vision_feature_dim,\n",
    "        fusion_output_size,\n",
    "        dropout_p):\n",
    "        super(LanguageAndVisionConcat, self).__init__()\n",
    "        self.nlp_module = nlp_module\n",
    "        self.vision_module = vision_module\n",
    "        self.fusion = torch.nn.Linear(\n",
    "                        in_features=(language_feature_dim + vision_feature_dim), \n",
    "                        out_features=fusion_output_size,\n",
    "        )\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(\n",
    "            in_features=fusion_output_size, \n",
    "            out_features=num_classes\n",
    "        )\n",
    "        \n",
    "   \n",
    "    \n",
    "    def forward(self, text, text2 , image):\n",
    "        text_features = torch.nn.functional.relu(\n",
    "            self.nlp_module(text, text2)\n",
    "        )\n",
    "        image_features = torch.nn.functional.relu(\n",
    "            self.vision_module(image)\n",
    "        )\n",
    "        combined = torch.cat(\n",
    "            [text_features, image_features], dim=1\n",
    "        )\n",
    "        fused = self.dropout(\n",
    "            torch.nn.functional.relu(\n",
    "            self.fusion(combined)\n",
    "            ))\n",
    "        logits = self.fc(fused)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e7a1acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageAndVisionConcat(\n",
       "  (nlp_module): BertClassifier(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dense): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=500, bias=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vision_module): resnet_classifier(\n",
       "    (resnet50): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fusion): Linear(in_features=1000, out_features=250, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=250, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LanguageAndVisionConcat(\n",
    "        nlp_module = NLP_module,\n",
    "        vision_module = vision_module,\n",
    "        num_classes = class_num,\n",
    "        language_feature_dim = 500,\n",
    "        vision_feature_dim = 500,\n",
    "        fusion_output_size = 250,\n",
    "        dropout_p = 0.2\n",
    ")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "824addf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6566e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_train =  dataloaders['train']\n",
    "vision_val =  dataloaders['val']\n",
    "vision_test =  dataloaders['test']\n",
    "\n",
    "nlp_train = train_dataloader\n",
    "nlp_val = val_dataloader\n",
    "nlp_test = test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73080d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH =\"C:/Users/ANDlab3/Desktop/VisionAndNLP/checkpoint/\"\n",
    "\n",
    "train_loss = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n",
    "eval_loss = []\n",
    "correct = 0\n",
    "total = 0\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "epoch = 11\n",
    "# log_interval = 100\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    time_epoch = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for nlp, vision in zip(nlp_train, vision_train):\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in nlp)\n",
    "        v_image, v_label = tuple(k.to(device) for k in vision)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, b_attn_mask, v_image)\n",
    "        loss = criterion(outputs, v_label) # 손실함수 계산\n",
    "        loss.backward() # 손실함수 기준으로 역전파 선언\n",
    "        optimizer.step() # 가중치 최적화\n",
    "  \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    train_loss.append(running_loss / len(vision_train))   \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_running_loss = 0.0\n",
    "        for nlp, vision in zip(nlp_val, vision_val):\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in nlp)\n",
    "            v_image, v_label = tuple(k.to(device) for k in vision)\n",
    "\n",
    "            outputs = model(b_input_ids, b_attn_mask, v_image) \n",
    "            val_loss = criterion(outputs, v_label) \n",
    "            eval_running_loss += val_loss.item()\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "\n",
    "            total += v_label.size(0)\n",
    "\n",
    "            correct += (pred == v_label).sum().item()\n",
    "            acc =  (100 * correct / total)\n",
    "    \n",
    "        eval_loss.append(eval_running_loss / len(vision_val)) \n",
    "        \n",
    "        time_elapsed = time.time() - time_epoch\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), PATH+str(epoch+1)+'_best_model.pt')\n",
    "            best_epoch = epoch+1\n",
    "        \n",
    "        print('[%d] Train loss: %.3f' %(epoch + 1, running_loss / len(vision_train))\n",
    "     ,' val loss: %.3f' %(eval_running_loss / len(vision_val))\n",
    "     ,'Acc:', round(acc*100,2) ,'time_elapsed:', round(time_elapsed),'second')\n",
    "        \n",
    "print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss)\n",
    "plt.legend(['train','validation'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18da3b7",
   "metadata": {},
   "source": [
    "# 베스트 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa43c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = model.to(device) # 모델 선언\n",
    "# best_model.load_state_dict(torch.load(PATH+str(best_epoch)+'_best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dcd420",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_total = 0\n",
    "test_correct = 0\n",
    "\n",
    "true = []\n",
    "test_pred = []\n",
    "# nlp_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for nlp, vision in zip(nlp_test, vision_test):\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in nlp)\n",
    "        v_image, v_label = tuple(k.to(device) for k in vision)\n",
    "\n",
    "        outputs = model(b_input_ids, b_attn_mask, v_image) \n",
    "\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        \n",
    "#         test = torch.argmax(outputs, 1)\n",
    "        \n",
    "        test_total += v_label.size(0)\n",
    "        test_correct += (pred == v_label).sum().item()\n",
    "        \n",
    "        true += v_label.cpu().numpy().tolist()\n",
    "#         nlp_true += b_labels.cpu().numpy().tolist()\n",
    "        test_pred += pred.cpu().numpy().tolist()        \n",
    "\n",
    "print('Accuracy of the network on the val data: %d %%' % (100 * test_correct / test_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ac2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report 저장\n",
    "CL_REPORT_FILE = \"./cl_report.csv\"\n",
    "\n",
    "cl_report = classification_report(true, test_pred, output_dict = True)\n",
    "cl_report_df = pd.DataFrame(cl_report).transpose()\n",
    "cl_report_df = cl_report_df.round(3)\n",
    "# cl_report_df.to_csv(CL_REPORT_FILE)\n",
    "print(cl_report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b659c452",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
