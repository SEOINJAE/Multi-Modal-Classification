{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4ea0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import re\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "                            roc_auc_score, confusion_matrix, classification_report, \\\n",
    "                            matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd0c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완벽한 실험 재현성을 위한 랜덤제어\n",
    "random_seed = 28\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.cuda.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37b2d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e35de",
   "metadata": {},
   "source": [
    "# NLP and Vision Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15da6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_train_path = \"C:/Users/ANDlab3/Desktop/VisionAndNLP/data/train.csv\"\n",
    "nlp_val_path = \"C:/Users/ANDlab3/Desktop/VisionAndNLP/data/val.csv\"\n",
    "nlp_test_path = \"C:/Users/ANDlab3/Desktop/VisionAndNLP/data/test.csv\"\n",
    "\n",
    "nlp_train_data = pd.read_csv(nlp_train_path)\n",
    "nlp_val_data = pd.read_csv(nlp_val_path)\n",
    "nlp_test_data = pd.read_csv(nlp_test_path)\n",
    "\n",
    "X_train = nlp_train_data['productDisplayName']\n",
    "y_train = nlp_train_data['label']\n",
    "\n",
    "X_val = nlp_val_data['productDisplayName']\n",
    "y_val = nlp_val_data['label']\n",
    "\n",
    "X_test = nlp_test_data['productDisplayName']\n",
    "y_test = nlp_test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee577bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f271f34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe47ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANDlab3\\anaconda3\\envs\\GAN\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2302: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 30\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)\n",
    "test_inputs, test_masks = preprocessing_for_bert(X_test)\n",
    "\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "test_labels = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c81f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "}\n",
    "\n",
    "image_path = \"C:/Users/ANDlab3/Desktop/paper/fashion-dataset/data/\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(image_path, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val','test']}\n",
    "\n",
    "# dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "#                                              shuffle=False, num_workers=4)\n",
    "#               for x in ['train', 'val','test']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16,\n",
    "                                             shuffle=False, num_workers=4)\n",
    "              for x in ['train', 'val','test']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "class_num = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c234cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img_temp = []\n",
    "val_img_label_temp = []\n",
    "for i, j in image_datasets['val']:\n",
    "    val_img_temp.append(i)\n",
    "    val_img_label_temp.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17fcd386",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_temp = []\n",
    "test_img_label_temp = []\n",
    "for i, j in image_datasets['test']:\n",
    "    test_img_temp.append(i)\n",
    "    test_img_label_temp.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a95be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_temp = []\n",
    "train_img_label_temp = []\n",
    "for i, j in image_datasets['train']:\n",
    "    train_img_temp.append(i)\n",
    "    train_img_label_temp.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765cdb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = torch.stack(train_img_temp, 0)\n",
    "train_img_label = torch.tensor(train_img_label_temp)\n",
    "\n",
    "val_img = torch.stack(val_img_temp, 0)\n",
    "val_img_label = torch.tensor(val_img_label_temp)\n",
    "\n",
    "test_img = torch.stack(test_img_temp, 0)\n",
    "test_img_label = torch.tensor(test_img_label_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f39d0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels, train_img, train_img_label)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels, val_img, val_img_label)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels, test_img, test_img_label)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd02c453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6475\n",
      "925\n",
      "1850\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4879de",
   "metadata": {},
   "source": [
    "# Vision Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48817e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "#Changing the number of outputs in the last layer to the number of different item types\n",
    "model_ft.fc = nn.Linear(num_ftrs, 500)\n",
    "pre_model= model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f98daf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_classifier(nn.Module):\n",
    "    def __init__(self, pre_model):\n",
    "        super(resnet_classifier, self).__init__()\n",
    "    \n",
    "        D_in, H, D_out = 1000, 500, 37\n",
    "        self.resnet50 = pre_model\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        outputs = self.resnet50(image)\n",
    "        \n",
    "        fc = self.classifier(outputs)\n",
    "        \n",
    "        return  fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "047cbbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet_classifier(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_module = resnet_classifier(pre_model)\n",
    "vision_module.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edba4cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SAVE_PATH = \"C:/Users/ANDlab3/Desktop/paper/fashion-dataset/model/\"\n",
    "vision_module.load_state_dict(torch.load(IMG_SAVE_PATH+'model_fine_tuned_v2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a6ddf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resnet_classifier(\n",
       "  (resnet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.2, inplace=False)\n",
       "    (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vision_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "451a9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 resnet50.conv1.weight\n",
      "1 resnet50.bn1.weight\n",
      "2 resnet50.bn1.bias\n",
      "3 resnet50.layer1.0.conv1.weight\n",
      "4 resnet50.layer1.0.bn1.weight\n",
      "5 resnet50.layer1.0.bn1.bias\n",
      "6 resnet50.layer1.0.conv2.weight\n",
      "7 resnet50.layer1.0.bn2.weight\n",
      "8 resnet50.layer1.0.bn2.bias\n",
      "9 resnet50.layer1.0.conv3.weight\n",
      "10 resnet50.layer1.0.bn3.weight\n",
      "11 resnet50.layer1.0.bn3.bias\n",
      "12 resnet50.layer1.0.downsample.0.weight\n",
      "13 resnet50.layer1.0.downsample.1.weight\n",
      "14 resnet50.layer1.0.downsample.1.bias\n",
      "15 resnet50.layer1.1.conv1.weight\n",
      "16 resnet50.layer1.1.bn1.weight\n",
      "17 resnet50.layer1.1.bn1.bias\n",
      "18 resnet50.layer1.1.conv2.weight\n",
      "19 resnet50.layer1.1.bn2.weight\n",
      "20 resnet50.layer1.1.bn2.bias\n",
      "21 resnet50.layer1.1.conv3.weight\n",
      "22 resnet50.layer1.1.bn3.weight\n",
      "23 resnet50.layer1.1.bn3.bias\n",
      "24 resnet50.layer1.2.conv1.weight\n",
      "25 resnet50.layer1.2.bn1.weight\n",
      "26 resnet50.layer1.2.bn1.bias\n",
      "27 resnet50.layer1.2.conv2.weight\n",
      "28 resnet50.layer1.2.bn2.weight\n",
      "29 resnet50.layer1.2.bn2.bias\n",
      "30 resnet50.layer1.2.conv3.weight\n",
      "31 resnet50.layer1.2.bn3.weight\n",
      "32 resnet50.layer1.2.bn3.bias\n",
      "33 resnet50.layer2.0.conv1.weight\n",
      "34 resnet50.layer2.0.bn1.weight\n",
      "35 resnet50.layer2.0.bn1.bias\n",
      "36 resnet50.layer2.0.conv2.weight\n",
      "37 resnet50.layer2.0.bn2.weight\n",
      "38 resnet50.layer2.0.bn2.bias\n",
      "39 resnet50.layer2.0.conv3.weight\n",
      "40 resnet50.layer2.0.bn3.weight\n",
      "41 resnet50.layer2.0.bn3.bias\n",
      "42 resnet50.layer2.0.downsample.0.weight\n",
      "43 resnet50.layer2.0.downsample.1.weight\n",
      "44 resnet50.layer2.0.downsample.1.bias\n",
      "45 resnet50.layer2.1.conv1.weight\n",
      "46 resnet50.layer2.1.bn1.weight\n",
      "47 resnet50.layer2.1.bn1.bias\n",
      "48 resnet50.layer2.1.conv2.weight\n",
      "49 resnet50.layer2.1.bn2.weight\n",
      "50 resnet50.layer2.1.bn2.bias\n",
      "51 resnet50.layer2.1.conv3.weight\n",
      "52 resnet50.layer2.1.bn3.weight\n",
      "53 resnet50.layer2.1.bn3.bias\n",
      "54 resnet50.layer2.2.conv1.weight\n",
      "55 resnet50.layer2.2.bn1.weight\n",
      "56 resnet50.layer2.2.bn1.bias\n",
      "57 resnet50.layer2.2.conv2.weight\n",
      "58 resnet50.layer2.2.bn2.weight\n",
      "59 resnet50.layer2.2.bn2.bias\n",
      "60 resnet50.layer2.2.conv3.weight\n",
      "61 resnet50.layer2.2.bn3.weight\n",
      "62 resnet50.layer2.2.bn3.bias\n",
      "63 resnet50.layer2.3.conv1.weight\n",
      "64 resnet50.layer2.3.bn1.weight\n",
      "65 resnet50.layer2.3.bn1.bias\n",
      "66 resnet50.layer2.3.conv2.weight\n",
      "67 resnet50.layer2.3.bn2.weight\n",
      "68 resnet50.layer2.3.bn2.bias\n",
      "69 resnet50.layer2.3.conv3.weight\n",
      "70 resnet50.layer2.3.bn3.weight\n",
      "71 resnet50.layer2.3.bn3.bias\n",
      "72 resnet50.layer3.0.conv1.weight\n",
      "73 resnet50.layer3.0.bn1.weight\n",
      "74 resnet50.layer3.0.bn1.bias\n",
      "75 resnet50.layer3.0.conv2.weight\n",
      "76 resnet50.layer3.0.bn2.weight\n",
      "77 resnet50.layer3.0.bn2.bias\n",
      "78 resnet50.layer3.0.conv3.weight\n",
      "79 resnet50.layer3.0.bn3.weight\n",
      "80 resnet50.layer3.0.bn3.bias\n",
      "81 resnet50.layer3.0.downsample.0.weight\n",
      "82 resnet50.layer3.0.downsample.1.weight\n",
      "83 resnet50.layer3.0.downsample.1.bias\n",
      "84 resnet50.layer3.1.conv1.weight\n",
      "85 resnet50.layer3.1.bn1.weight\n",
      "86 resnet50.layer3.1.bn1.bias\n",
      "87 resnet50.layer3.1.conv2.weight\n",
      "88 resnet50.layer3.1.bn2.weight\n",
      "89 resnet50.layer3.1.bn2.bias\n",
      "90 resnet50.layer3.1.conv3.weight\n",
      "91 resnet50.layer3.1.bn3.weight\n",
      "92 resnet50.layer3.1.bn3.bias\n",
      "93 resnet50.layer3.2.conv1.weight\n",
      "94 resnet50.layer3.2.bn1.weight\n",
      "95 resnet50.layer3.2.bn1.bias\n",
      "96 resnet50.layer3.2.conv2.weight\n",
      "97 resnet50.layer3.2.bn2.weight\n",
      "98 resnet50.layer3.2.bn2.bias\n",
      "99 resnet50.layer3.2.conv3.weight\n",
      "100 resnet50.layer3.2.bn3.weight\n",
      "101 resnet50.layer3.2.bn3.bias\n",
      "102 resnet50.layer3.3.conv1.weight\n",
      "103 resnet50.layer3.3.bn1.weight\n",
      "104 resnet50.layer3.3.bn1.bias\n",
      "105 resnet50.layer3.3.conv2.weight\n",
      "106 resnet50.layer3.3.bn2.weight\n",
      "107 resnet50.layer3.3.bn2.bias\n",
      "108 resnet50.layer3.3.conv3.weight\n",
      "109 resnet50.layer3.3.bn3.weight\n",
      "110 resnet50.layer3.3.bn3.bias\n",
      "111 resnet50.layer3.4.conv1.weight\n",
      "112 resnet50.layer3.4.bn1.weight\n",
      "113 resnet50.layer3.4.bn1.bias\n",
      "114 resnet50.layer3.4.conv2.weight\n",
      "115 resnet50.layer3.4.bn2.weight\n",
      "116 resnet50.layer3.4.bn2.bias\n",
      "117 resnet50.layer3.4.conv3.weight\n",
      "118 resnet50.layer3.4.bn3.weight\n",
      "119 resnet50.layer3.4.bn3.bias\n",
      "120 resnet50.layer3.5.conv1.weight\n",
      "121 resnet50.layer3.5.bn1.weight\n",
      "122 resnet50.layer3.5.bn1.bias\n",
      "123 resnet50.layer3.5.conv2.weight\n",
      "124 resnet50.layer3.5.bn2.weight\n",
      "125 resnet50.layer3.5.bn2.bias\n",
      "126 resnet50.layer3.5.conv3.weight\n",
      "127 resnet50.layer3.5.bn3.weight\n",
      "128 resnet50.layer3.5.bn3.bias\n",
      "129 resnet50.layer4.0.conv1.weight\n",
      "130 resnet50.layer4.0.bn1.weight\n",
      "131 resnet50.layer4.0.bn1.bias\n",
      "132 resnet50.layer4.0.conv2.weight\n",
      "133 resnet50.layer4.0.bn2.weight\n",
      "134 resnet50.layer4.0.bn2.bias\n",
      "135 resnet50.layer4.0.conv3.weight\n",
      "136 resnet50.layer4.0.bn3.weight\n",
      "137 resnet50.layer4.0.bn3.bias\n",
      "138 resnet50.layer4.0.downsample.0.weight\n",
      "139 resnet50.layer4.0.downsample.1.weight\n",
      "140 resnet50.layer4.0.downsample.1.bias\n",
      "141 resnet50.layer4.1.conv1.weight\n",
      "142 resnet50.layer4.1.bn1.weight\n",
      "143 resnet50.layer4.1.bn1.bias\n",
      "144 resnet50.layer4.1.conv2.weight\n",
      "145 resnet50.layer4.1.bn2.weight\n",
      "146 resnet50.layer4.1.bn2.bias\n",
      "147 resnet50.layer4.1.conv3.weight\n",
      "148 resnet50.layer4.1.bn3.weight\n",
      "149 resnet50.layer4.1.bn3.bias\n",
      "150 resnet50.layer4.2.conv1.weight\n",
      "151 resnet50.layer4.2.bn1.weight\n",
      "152 resnet50.layer4.2.bn1.bias\n",
      "153 resnet50.layer4.2.conv2.weight\n",
      "154 resnet50.layer4.2.bn2.weight\n",
      "155 resnet50.layer4.2.bn2.bias\n",
      "156 resnet50.layer4.2.conv3.weight\n",
      "157 resnet50.layer4.2.bn3.weight\n",
      "158 resnet50.layer4.2.bn3.bias\n",
      "159 resnet50.fc.weight\n",
      "160 resnet50.fc.bias\n",
      "161 classifier.2.weight\n",
      "162 classifier.2.bias\n"
     ]
    }
   ],
   "source": [
    "# 파라메타 번호 확인 하기\n",
    "i = 0\n",
    "for name, param in vision_module.named_parameters():\n",
    "    \n",
    "    print(i,name)\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60dba931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(vision_module.named_parameters()):\n",
    "    \n",
    "    param.requires_grad = False\n",
    "    if i == 158:\n",
    "        print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3459328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('resnet50.conv1.weight', Parameter containing:\n",
      "tensor([[[[ 2.9832e-02,  2.7486e-02, -5.4940e-04,  ..., -1.5218e-02,\n",
      "           -1.4472e-02, -4.5599e-02],\n",
      "          [ 1.7806e-02,  1.4144e-02,  2.7383e-02,  ...,  2.5815e-02,\n",
      "            3.9620e-03, -1.4788e-02],\n",
      "          [ 3.1399e-02,  2.4234e-02,  2.0323e-02,  ...,  1.1810e-01,\n",
      "            8.3817e-02,  7.4766e-02],\n",
      "          ...,\n",
      "          [ 8.8523e-03,  3.3135e-02, -2.9771e-03,  ..., -1.2287e-01,\n",
      "           -6.9704e-02,  1.5388e-02],\n",
      "          [ 2.0160e-02,  5.8223e-02,  7.5046e-02,  ...,  3.1977e-02,\n",
      "           -2.5193e-02, -7.6963e-03],\n",
      "          [-6.8655e-02, -2.2381e-02, -3.6866e-03,  ...,  5.2400e-02,\n",
      "            4.0082e-02,  1.5968e-02]],\n",
      "\n",
      "         [[ 2.5577e-03,  2.6901e-02,  3.7032e-02,  ...,  8.2444e-02,\n",
      "            7.5451e-02,  1.6257e-02],\n",
      "          [ 1.6055e-02,  3.5968e-02,  8.7621e-02,  ...,  1.9196e-01,\n",
      "            1.7871e-01,  1.4971e-01],\n",
      "          [-2.9695e-02, -6.6044e-02, -7.6467e-02,  ...,  1.4619e-01,\n",
      "            1.9754e-01,  2.0638e-01],\n",
      "          ...,\n",
      "          [ 3.8649e-02,  1.6417e-02, -7.9462e-02,  ..., -3.6901e-01,\n",
      "           -2.8917e-01, -1.2853e-01],\n",
      "          [ 1.0221e-01,  1.4520e-01,  1.5985e-01,  ...,  4.3640e-03,\n",
      "           -1.1093e-01, -1.2078e-01],\n",
      "          [ 5.5359e-03,  7.9985e-02,  1.4403e-01,  ...,  1.9619e-01,\n",
      "            1.2703e-01,  3.2209e-02]],\n",
      "\n",
      "         [[-1.4120e-03,  3.1868e-03,  1.3561e-02,  ...,  4.3952e-02,\n",
      "            4.9939e-02,  1.5254e-02],\n",
      "          [ 1.1132e-02,  1.8388e-02,  6.5394e-02,  ...,  1.5035e-01,\n",
      "            1.4673e-01,  1.3538e-01],\n",
      "          [-4.8756e-02, -9.3940e-02, -8.9665e-02,  ...,  1.2344e-01,\n",
      "            1.6278e-01,  1.7212e-01],\n",
      "          ...,\n",
      "          [ 3.3724e-02,  1.4032e-02, -7.0524e-02,  ..., -3.1058e-01,\n",
      "           -2.4796e-01, -1.1975e-01],\n",
      "          [ 9.0138e-02,  1.2291e-01,  1.4215e-01,  ..., -6.0041e-04,\n",
      "           -1.1674e-01, -1.2038e-01],\n",
      "          [ 8.0072e-03,  7.6705e-02,  1.3271e-01,  ...,  2.0332e-01,\n",
      "            1.2784e-01,  3.1467e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3271e-01,  7.4851e-02,  9.1012e-02,  ...,  6.3618e-02,\n",
      "            8.5126e-02,  9.5804e-02],\n",
      "          [ 8.9751e-02,  2.0948e-02,  3.0564e-02,  ..., -6.1650e-02,\n",
      "           -3.3364e-02, -1.3727e-02],\n",
      "          [ 7.7827e-02,  8.2469e-03, -4.1489e-03,  ..., -1.4861e-01,\n",
      "           -1.0536e-01, -5.3553e-02],\n",
      "          ...,\n",
      "          [ 2.4635e-02, -8.5861e-02, -1.3572e-01,  ..., -2.5531e-01,\n",
      "           -2.3069e-01, -2.0212e-01],\n",
      "          [ 7.2842e-02, -3.8811e-02, -7.6123e-02,  ..., -2.4902e-01,\n",
      "           -1.9295e-01, -1.5888e-01],\n",
      "          [ 7.7172e-02, -1.8420e-02, -7.2531e-02,  ..., -1.9070e-01,\n",
      "           -1.4938e-01, -9.1780e-02]],\n",
      "\n",
      "         [[-5.8947e-02, -6.1185e-02, -5.9291e-02,  ..., -5.4714e-04,\n",
      "           -3.9314e-02, -5.2495e-02],\n",
      "          [-4.8564e-02, -4.1440e-02, -3.4921e-03,  ...,  5.6664e-02,\n",
      "            3.0921e-02, -7.0000e-03],\n",
      "          [-7.6646e-02, -3.4532e-02,  3.5828e-02,  ...,  1.9704e-01,\n",
      "            1.6581e-01,  1.0396e-01],\n",
      "          ...,\n",
      "          [-1.9435e-02,  5.6184e-02,  1.7815e-01,  ...,  4.9767e-01,\n",
      "            4.3149e-01,  2.9840e-01],\n",
      "          [-3.0291e-02,  2.0037e-02,  1.4077e-01,  ...,  3.9018e-01,\n",
      "            3.6356e-01,  2.4377e-01],\n",
      "          [-6.9369e-02, -3.0004e-02,  3.7036e-02,  ...,  2.2685e-01,\n",
      "            2.1125e-01,  1.6363e-01]],\n",
      "\n",
      "         [[ 4.5995e-02,  2.6833e-02,  9.7864e-04,  ...,  3.7596e-02,\n",
      "            3.9249e-02,  4.7017e-02],\n",
      "          [ 3.2158e-02,  1.1715e-02, -1.6004e-02,  ..., -1.6968e-02,\n",
      "           -9.2334e-03,  1.1616e-02],\n",
      "          [ 1.2987e-02, -1.4293e-02, -3.4818e-02,  ..., -1.0427e-01,\n",
      "           -9.0563e-02, -3.0713e-02],\n",
      "          ...,\n",
      "          [ 2.9983e-02, -1.8384e-02, -8.2697e-02,  ..., -1.6377e-01,\n",
      "           -1.3468e-01, -2.8409e-02],\n",
      "          [ 4.3048e-02, -2.0435e-02, -6.1671e-02,  ..., -1.4584e-01,\n",
      "           -9.9651e-02, -1.4591e-02],\n",
      "          [ 5.7596e-02,  1.4875e-02, -3.2632e-02,  ..., -5.7782e-02,\n",
      "           -3.9640e-02,  3.6577e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0623e-03,  1.1488e-02, -3.4543e-04,  ..., -2.9513e-02,\n",
      "           -1.5233e-02, -1.8997e-02],\n",
      "          [ 2.4412e-02,  3.8699e-02,  2.8377e-02,  ...,  5.2280e-03,\n",
      "            9.6643e-03, -1.5581e-02],\n",
      "          [ 1.8175e-02,  3.9383e-02,  3.2510e-02,  ...,  3.1704e-02,\n",
      "            1.9822e-02,  1.0895e-02],\n",
      "          ...,\n",
      "          [-1.0035e-04,  1.8798e-02,  7.1117e-03,  ...,  4.7639e-02,\n",
      "            6.9934e-02,  1.0210e-01],\n",
      "          [-1.7083e-02,  1.5641e-02,  9.8230e-03,  ...,  1.5137e-02,\n",
      "            3.9346e-02,  1.0326e-01],\n",
      "          [-2.7094e-02,  7.4912e-04,  2.9070e-03,  ...,  2.6333e-03,\n",
      "            4.3820e-02,  1.1574e-01]],\n",
      "\n",
      "         [[ 9.3606e-04, -8.1584e-03, -1.1100e-02,  ...,  1.9935e-02,\n",
      "            5.8835e-02,  6.2273e-02],\n",
      "          [ 9.9546e-03,  8.0890e-04, -9.2377e-03,  ...,  3.0137e-02,\n",
      "            6.6059e-02,  4.0550e-02],\n",
      "          [-8.4490e-03, -1.5853e-02, -3.1655e-02,  ...,  4.6624e-02,\n",
      "            6.2607e-02,  3.9374e-02],\n",
      "          ...,\n",
      "          [-3.1015e-02, -5.5424e-02, -1.0006e-01,  ..., -5.6845e-02,\n",
      "           -1.3197e-02,  1.6868e-02],\n",
      "          [-1.5185e-02, -1.6850e-02, -5.8745e-02,  ..., -9.7913e-02,\n",
      "           -6.6496e-02, -2.8630e-03],\n",
      "          [ 7.4554e-03,  7.2138e-03, -1.8749e-02,  ..., -7.0938e-02,\n",
      "           -4.2350e-02,  7.0248e-03]],\n",
      "\n",
      "         [[ 3.1754e-03, -4.8923e-02, -3.7162e-02,  ...,  3.2832e-02,\n",
      "            9.3294e-02,  7.1710e-02],\n",
      "          [-2.7841e-02, -8.5001e-02, -8.0196e-02,  ..., -1.1503e-02,\n",
      "            3.1507e-02, -1.7723e-02],\n",
      "          [-1.2005e-02, -7.3486e-02, -8.7667e-02,  ..., -4.2959e-03,\n",
      "            6.4790e-03, -3.6188e-02],\n",
      "          ...,\n",
      "          [-1.8390e-02, -8.1327e-02, -1.1947e-01,  ..., -1.0819e-01,\n",
      "           -9.8030e-02, -1.0934e-01],\n",
      "          [ 4.7277e-03, -3.0742e-02, -6.8087e-02,  ..., -1.2710e-01,\n",
      "           -1.4065e-01, -1.2190e-01],\n",
      "          [ 3.9688e-02, -1.3090e-03, -2.5759e-02,  ..., -9.7919e-02,\n",
      "           -1.1318e-01, -1.0320e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.6070e-02,  2.2761e-02,  2.7596e-02,  ..., -7.2084e-03,\n",
      "            4.3820e-02, -8.8459e-03],\n",
      "          [-2.8920e-02,  4.6527e-02,  4.5462e-02,  ..., -7.0489e-02,\n",
      "            8.7716e-02, -3.0074e-02],\n",
      "          [-6.7906e-02,  8.4036e-02,  4.4417e-02,  ..., -1.0491e-01,\n",
      "            1.6031e-01, -2.5267e-02],\n",
      "          ...,\n",
      "          [ 3.8494e-03,  1.2276e-01, -6.0471e-02,  ...,  6.6186e-02,\n",
      "            1.8485e-01, -1.4808e-02],\n",
      "          [ 1.0694e-02,  6.1068e-02, -7.1778e-02,  ...,  5.4177e-02,\n",
      "            1.1649e-01, -2.3087e-02],\n",
      "          [ 2.8992e-02,  9.2142e-03, -6.7087e-02,  ...,  5.9826e-02,\n",
      "            7.5215e-02,  5.9201e-03]],\n",
      "\n",
      "         [[ 2.1897e-02,  6.1949e-02,  1.9688e-02,  ..., -6.0848e-02,\n",
      "            5.2893e-02,  4.3613e-02],\n",
      "          [ 4.4952e-03,  1.2972e-01,  3.3943e-02,  ..., -1.5776e-01,\n",
      "            1.4379e-01,  6.5267e-02],\n",
      "          [-3.1410e-03,  2.0723e-01,  1.2444e-02,  ..., -2.0151e-01,\n",
      "            2.6172e-01,  8.7624e-02],\n",
      "          ...,\n",
      "          [ 4.8845e-02,  1.8702e-01, -1.5732e-01,  ...,  3.7393e-02,\n",
      "            3.0313e-01,  6.3754e-02],\n",
      "          [ 3.2461e-02,  8.9434e-02, -1.5658e-01,  ...,  5.0389e-02,\n",
      "            1.7973e-01, -8.4554e-03],\n",
      "          [ 3.1252e-02,  3.1645e-02, -1.1128e-01,  ...,  7.3560e-02,\n",
      "            9.8823e-02, -6.2564e-03]],\n",
      "\n",
      "         [[ 1.7156e-02,  4.3317e-02,  3.9017e-02,  ..., -2.9908e-02,\n",
      "            1.6836e-02,  7.5857e-03],\n",
      "          [-2.1170e-02,  8.3197e-02,  8.1931e-02,  ..., -5.9689e-02,\n",
      "            7.6334e-02, -2.6882e-03],\n",
      "          [-4.9813e-02,  1.1874e-01,  7.7675e-02,  ..., -8.6904e-02,\n",
      "            1.3565e-01, -1.3008e-02],\n",
      "          ...,\n",
      "          [-2.2131e-03,  1.1224e-01, -5.7788e-02,  ...,  3.8179e-02,\n",
      "            1.4170e-01, -1.8931e-02],\n",
      "          [-2.3793e-03,  6.0094e-02, -5.9870e-02,  ...,  3.2165e-02,\n",
      "            8.4279e-02, -4.3699e-02],\n",
      "          [ 1.5113e-02,  3.2180e-02, -4.3053e-02,  ...,  4.1944e-02,\n",
      "            4.4832e-02, -2.9555e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8371e-02,  2.3111e-02,  2.7255e-02,  ..., -7.9225e-02,\n",
      "           -3.9082e-02, -2.1738e-03],\n",
      "          [ 6.2171e-02,  4.0080e-02,  2.8668e-02,  ..., -1.8162e-01,\n",
      "           -1.2781e-01, -4.3833e-02],\n",
      "          [ 8.9873e-02,  5.9355e-02,  3.5261e-02,  ..., -3.0577e-01,\n",
      "           -1.6353e-01, -3.4066e-02],\n",
      "          ...,\n",
      "          [ 2.1928e-03, -6.8306e-02, -2.2451e-01,  ..., -3.7706e-01,\n",
      "           -1.8694e-01,  4.9783e-02],\n",
      "          [ 2.1930e-02, -5.1446e-02, -1.7303e-01,  ..., -3.1269e-01,\n",
      "           -4.1651e-02,  1.0837e-01],\n",
      "          [ 3.3756e-02, -3.2420e-02, -1.3619e-01,  ..., -2.1012e-01,\n",
      "            3.3837e-02,  1.4725e-01]],\n",
      "\n",
      "         [[ 3.8938e-03,  3.4659e-03,  2.0930e-02,  ..., -5.7709e-03,\n",
      "            9.1954e-05,  1.3016e-02],\n",
      "          [ 5.1793e-02,  2.0787e-02,  3.8423e-02,  ..., -1.0601e-02,\n",
      "           -5.9145e-03,  1.0909e-02],\n",
      "          [ 4.5666e-02,  1.3958e-02,  4.8802e-02,  ..., -7.3842e-02,\n",
      "            4.8122e-04,  3.1996e-02],\n",
      "          ...,\n",
      "          [-3.7414e-03, -7.8300e-03, -5.9151e-02,  ..., -7.1368e-02,\n",
      "           -4.0398e-02,  6.8512e-02],\n",
      "          [ 3.1019e-02,  1.2100e-02, -1.1089e-02,  ..., -8.3419e-02,\n",
      "            1.7786e-02,  5.8466e-02],\n",
      "          [ 5.3996e-02,  3.4123e-02,  1.5589e-02,  ..., -4.0828e-02,\n",
      "            4.5201e-02,  5.8432e-02]],\n",
      "\n",
      "         [[-4.5272e-02, -4.1040e-02, -2.9606e-02,  ..., -8.5395e-03,\n",
      "           -2.3394e-03, -1.4117e-02],\n",
      "          [-5.3652e-03, -2.6565e-02, -1.1860e-03,  ...,  2.4939e-02,\n",
      "            1.7292e-02,  7.2781e-04],\n",
      "          [-2.1058e-02, -4.5718e-02,  1.3222e-02,  ...,  1.5375e-02,\n",
      "            3.9057e-02, -3.5208e-03],\n",
      "          ...,\n",
      "          [-2.2208e-02, -2.3465e-03,  1.0345e-02,  ...,  3.9315e-02,\n",
      "           -1.3557e-02, -2.1662e-02],\n",
      "          [ 9.7192e-03,  2.1227e-02,  5.4671e-02,  ...,  2.5527e-02,\n",
      "            2.3256e-02, -3.0518e-02],\n",
      "          [ 2.3091e-02,  3.4216e-02,  6.2642e-02,  ...,  1.8940e-02,\n",
      "            2.0503e-02, -3.0864e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9478e-02, -3.2873e-02,  5.9774e-02,  ..., -4.6018e-02,\n",
      "            1.8675e-02,  1.2231e-02],\n",
      "          [-4.3079e-02,  5.6632e-02, -2.1258e-02,  ...,  3.0026e-02,\n",
      "           -9.9150e-04,  7.7578e-03],\n",
      "          [ 4.8381e-02, -4.3220e-02, -2.9631e-02,  ..., -2.0782e-01,\n",
      "            1.6216e-02,  5.3352e-02],\n",
      "          ...,\n",
      "          [-4.3521e-02,  7.8935e-02,  1.0564e-01,  ...,  5.3064e-01,\n",
      "           -4.1808e-02, -4.7158e-02],\n",
      "          [-2.1037e-02,  9.5506e-02, -2.1430e-01,  ...,  2.4240e-01,\n",
      "           -2.6944e-01,  1.2488e-01],\n",
      "          [-2.4825e-02, -2.8892e-03, -8.5831e-02,  ..., -5.1214e-02,\n",
      "            2.3550e-02, -3.4383e-02]],\n",
      "\n",
      "         [[ 2.5060e-02, -3.3351e-02,  4.7969e-02,  ..., -3.8486e-02,\n",
      "            2.5506e-02, -1.2564e-02],\n",
      "          [-3.8157e-02,  7.3537e-02, -5.8115e-03,  ...,  3.5514e-02,\n",
      "            9.0174e-03, -2.2288e-03],\n",
      "          [ 3.8378e-02, -5.3688e-02, -5.4205e-04,  ..., -2.5824e-01,\n",
      "            5.6706e-02,  3.1391e-02],\n",
      "          ...,\n",
      "          [-3.1422e-02,  1.3460e-01,  1.2487e-01,  ...,  6.6170e-01,\n",
      "           -2.9088e-02, -1.3989e-01],\n",
      "          [-2.2524e-02,  1.2714e-01, -2.5744e-01,  ...,  3.3856e-01,\n",
      "           -3.4760e-01,  6.3871e-02],\n",
      "          [-1.2893e-03,  2.5026e-02, -8.5834e-02,  ..., -6.6333e-02,\n",
      "           -8.0265e-03, -4.1694e-02]],\n",
      "\n",
      "         [[ 1.8265e-02, -3.1175e-02,  2.5749e-02,  ..., -4.5550e-02,\n",
      "            2.1465e-02, -5.8320e-03],\n",
      "          [-2.6700e-02,  8.5125e-02, -1.5873e-02,  ...,  5.0798e-02,\n",
      "           -3.6249e-03, -1.5388e-02],\n",
      "          [ 6.6158e-02, -3.3813e-02, -1.1655e-01,  ..., -1.3073e-01,\n",
      "            7.7335e-03,  9.6899e-03],\n",
      "          ...,\n",
      "          [-6.1366e-03,  1.7147e-02,  1.5110e-01,  ...,  4.7100e-01,\n",
      "           -1.7864e-01, -3.9830e-02],\n",
      "          [-4.3827e-02,  4.5814e-02, -1.2647e-01,  ...,  1.1271e-01,\n",
      "           -2.9888e-01,  1.4575e-01],\n",
      "          [ 1.0878e-02,  2.3981e-02, -8.9030e-03,  ..., -1.0612e-01,\n",
      "            4.8510e-02, -2.1200e-02]]]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "for p in vision_module.named_parameters():\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668d386",
   "metadata": {},
   "source": [
    "# NLP Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ba469c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 500, 37\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.dense = nn.Sequential(\n",
    "                nn.Linear(D_in, H),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "#         # Freeze the BERT model\n",
    "#         if freeze_bert:\n",
    "#             for param in self.bert.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        \n",
    "        dense = self.dense(last_hidden_state_cls)\n",
    "        logits = self.classifier(dense)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce618bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dense): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=500, bias=True)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_module = BertClassifier()\n",
    "NLP_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c38910ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP_SAVE_PATH = \"C:/Users/ANDlab3/Desktop/NLP/model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cab9799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NLP_module= NLP_module.to(device) # 모델 선언\n",
    "NLP_module.load_state_dict(torch.load(NLP_SAVE_PATH+'bert_fine_tuned_v2.pt')) # 모델 파라메타 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0630946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bert.embeddings.word_embeddings.weight\n",
      "1 bert.embeddings.position_embeddings.weight\n",
      "2 bert.embeddings.token_type_embeddings.weight\n",
      "3 bert.embeddings.LayerNorm.weight\n",
      "4 bert.embeddings.LayerNorm.bias\n",
      "5 bert.encoder.layer.0.attention.self.query.weight\n",
      "6 bert.encoder.layer.0.attention.self.query.bias\n",
      "7 bert.encoder.layer.0.attention.self.key.weight\n",
      "8 bert.encoder.layer.0.attention.self.key.bias\n",
      "9 bert.encoder.layer.0.attention.self.value.weight\n",
      "10 bert.encoder.layer.0.attention.self.value.bias\n",
      "11 bert.encoder.layer.0.attention.output.dense.weight\n",
      "12 bert.encoder.layer.0.attention.output.dense.bias\n",
      "13 bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "14 bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "15 bert.encoder.layer.0.intermediate.dense.weight\n",
      "16 bert.encoder.layer.0.intermediate.dense.bias\n",
      "17 bert.encoder.layer.0.output.dense.weight\n",
      "18 bert.encoder.layer.0.output.dense.bias\n",
      "19 bert.encoder.layer.0.output.LayerNorm.weight\n",
      "20 bert.encoder.layer.0.output.LayerNorm.bias\n",
      "21 bert.encoder.layer.1.attention.self.query.weight\n",
      "22 bert.encoder.layer.1.attention.self.query.bias\n",
      "23 bert.encoder.layer.1.attention.self.key.weight\n",
      "24 bert.encoder.layer.1.attention.self.key.bias\n",
      "25 bert.encoder.layer.1.attention.self.value.weight\n",
      "26 bert.encoder.layer.1.attention.self.value.bias\n",
      "27 bert.encoder.layer.1.attention.output.dense.weight\n",
      "28 bert.encoder.layer.1.attention.output.dense.bias\n",
      "29 bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "30 bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "31 bert.encoder.layer.1.intermediate.dense.weight\n",
      "32 bert.encoder.layer.1.intermediate.dense.bias\n",
      "33 bert.encoder.layer.1.output.dense.weight\n",
      "34 bert.encoder.layer.1.output.dense.bias\n",
      "35 bert.encoder.layer.1.output.LayerNorm.weight\n",
      "36 bert.encoder.layer.1.output.LayerNorm.bias\n",
      "37 bert.encoder.layer.2.attention.self.query.weight\n",
      "38 bert.encoder.layer.2.attention.self.query.bias\n",
      "39 bert.encoder.layer.2.attention.self.key.weight\n",
      "40 bert.encoder.layer.2.attention.self.key.bias\n",
      "41 bert.encoder.layer.2.attention.self.value.weight\n",
      "42 bert.encoder.layer.2.attention.self.value.bias\n",
      "43 bert.encoder.layer.2.attention.output.dense.weight\n",
      "44 bert.encoder.layer.2.attention.output.dense.bias\n",
      "45 bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "46 bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "47 bert.encoder.layer.2.intermediate.dense.weight\n",
      "48 bert.encoder.layer.2.intermediate.dense.bias\n",
      "49 bert.encoder.layer.2.output.dense.weight\n",
      "50 bert.encoder.layer.2.output.dense.bias\n",
      "51 bert.encoder.layer.2.output.LayerNorm.weight\n",
      "52 bert.encoder.layer.2.output.LayerNorm.bias\n",
      "53 bert.encoder.layer.3.attention.self.query.weight\n",
      "54 bert.encoder.layer.3.attention.self.query.bias\n",
      "55 bert.encoder.layer.3.attention.self.key.weight\n",
      "56 bert.encoder.layer.3.attention.self.key.bias\n",
      "57 bert.encoder.layer.3.attention.self.value.weight\n",
      "58 bert.encoder.layer.3.attention.self.value.bias\n",
      "59 bert.encoder.layer.3.attention.output.dense.weight\n",
      "60 bert.encoder.layer.3.attention.output.dense.bias\n",
      "61 bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "62 bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "63 bert.encoder.layer.3.intermediate.dense.weight\n",
      "64 bert.encoder.layer.3.intermediate.dense.bias\n",
      "65 bert.encoder.layer.3.output.dense.weight\n",
      "66 bert.encoder.layer.3.output.dense.bias\n",
      "67 bert.encoder.layer.3.output.LayerNorm.weight\n",
      "68 bert.encoder.layer.3.output.LayerNorm.bias\n",
      "69 bert.encoder.layer.4.attention.self.query.weight\n",
      "70 bert.encoder.layer.4.attention.self.query.bias\n",
      "71 bert.encoder.layer.4.attention.self.key.weight\n",
      "72 bert.encoder.layer.4.attention.self.key.bias\n",
      "73 bert.encoder.layer.4.attention.self.value.weight\n",
      "74 bert.encoder.layer.4.attention.self.value.bias\n",
      "75 bert.encoder.layer.4.attention.output.dense.weight\n",
      "76 bert.encoder.layer.4.attention.output.dense.bias\n",
      "77 bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "78 bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "79 bert.encoder.layer.4.intermediate.dense.weight\n",
      "80 bert.encoder.layer.4.intermediate.dense.bias\n",
      "81 bert.encoder.layer.4.output.dense.weight\n",
      "82 bert.encoder.layer.4.output.dense.bias\n",
      "83 bert.encoder.layer.4.output.LayerNorm.weight\n",
      "84 bert.encoder.layer.4.output.LayerNorm.bias\n",
      "85 bert.encoder.layer.5.attention.self.query.weight\n",
      "86 bert.encoder.layer.5.attention.self.query.bias\n",
      "87 bert.encoder.layer.5.attention.self.key.weight\n",
      "88 bert.encoder.layer.5.attention.self.key.bias\n",
      "89 bert.encoder.layer.5.attention.self.value.weight\n",
      "90 bert.encoder.layer.5.attention.self.value.bias\n",
      "91 bert.encoder.layer.5.attention.output.dense.weight\n",
      "92 bert.encoder.layer.5.attention.output.dense.bias\n",
      "93 bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "94 bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "95 bert.encoder.layer.5.intermediate.dense.weight\n",
      "96 bert.encoder.layer.5.intermediate.dense.bias\n",
      "97 bert.encoder.layer.5.output.dense.weight\n",
      "98 bert.encoder.layer.5.output.dense.bias\n",
      "99 bert.encoder.layer.5.output.LayerNorm.weight\n",
      "100 bert.encoder.layer.5.output.LayerNorm.bias\n",
      "101 bert.encoder.layer.6.attention.self.query.weight\n",
      "102 bert.encoder.layer.6.attention.self.query.bias\n",
      "103 bert.encoder.layer.6.attention.self.key.weight\n",
      "104 bert.encoder.layer.6.attention.self.key.bias\n",
      "105 bert.encoder.layer.6.attention.self.value.weight\n",
      "106 bert.encoder.layer.6.attention.self.value.bias\n",
      "107 bert.encoder.layer.6.attention.output.dense.weight\n",
      "108 bert.encoder.layer.6.attention.output.dense.bias\n",
      "109 bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "110 bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "111 bert.encoder.layer.6.intermediate.dense.weight\n",
      "112 bert.encoder.layer.6.intermediate.dense.bias\n",
      "113 bert.encoder.layer.6.output.dense.weight\n",
      "114 bert.encoder.layer.6.output.dense.bias\n",
      "115 bert.encoder.layer.6.output.LayerNorm.weight\n",
      "116 bert.encoder.layer.6.output.LayerNorm.bias\n",
      "117 bert.encoder.layer.7.attention.self.query.weight\n",
      "118 bert.encoder.layer.7.attention.self.query.bias\n",
      "119 bert.encoder.layer.7.attention.self.key.weight\n",
      "120 bert.encoder.layer.7.attention.self.key.bias\n",
      "121 bert.encoder.layer.7.attention.self.value.weight\n",
      "122 bert.encoder.layer.7.attention.self.value.bias\n",
      "123 bert.encoder.layer.7.attention.output.dense.weight\n",
      "124 bert.encoder.layer.7.attention.output.dense.bias\n",
      "125 bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "126 bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "127 bert.encoder.layer.7.intermediate.dense.weight\n",
      "128 bert.encoder.layer.7.intermediate.dense.bias\n",
      "129 bert.encoder.layer.7.output.dense.weight\n",
      "130 bert.encoder.layer.7.output.dense.bias\n",
      "131 bert.encoder.layer.7.output.LayerNorm.weight\n",
      "132 bert.encoder.layer.7.output.LayerNorm.bias\n",
      "133 bert.encoder.layer.8.attention.self.query.weight\n",
      "134 bert.encoder.layer.8.attention.self.query.bias\n",
      "135 bert.encoder.layer.8.attention.self.key.weight\n",
      "136 bert.encoder.layer.8.attention.self.key.bias\n",
      "137 bert.encoder.layer.8.attention.self.value.weight\n",
      "138 bert.encoder.layer.8.attention.self.value.bias\n",
      "139 bert.encoder.layer.8.attention.output.dense.weight\n",
      "140 bert.encoder.layer.8.attention.output.dense.bias\n",
      "141 bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "142 bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "143 bert.encoder.layer.8.intermediate.dense.weight\n",
      "144 bert.encoder.layer.8.intermediate.dense.bias\n",
      "145 bert.encoder.layer.8.output.dense.weight\n",
      "146 bert.encoder.layer.8.output.dense.bias\n",
      "147 bert.encoder.layer.8.output.LayerNorm.weight\n",
      "148 bert.encoder.layer.8.output.LayerNorm.bias\n",
      "149 bert.encoder.layer.9.attention.self.query.weight\n",
      "150 bert.encoder.layer.9.attention.self.query.bias\n",
      "151 bert.encoder.layer.9.attention.self.key.weight\n",
      "152 bert.encoder.layer.9.attention.self.key.bias\n",
      "153 bert.encoder.layer.9.attention.self.value.weight\n",
      "154 bert.encoder.layer.9.attention.self.value.bias\n",
      "155 bert.encoder.layer.9.attention.output.dense.weight\n",
      "156 bert.encoder.layer.9.attention.output.dense.bias\n",
      "157 bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "158 bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "159 bert.encoder.layer.9.intermediate.dense.weight\n",
      "160 bert.encoder.layer.9.intermediate.dense.bias\n",
      "161 bert.encoder.layer.9.output.dense.weight\n",
      "162 bert.encoder.layer.9.output.dense.bias\n",
      "163 bert.encoder.layer.9.output.LayerNorm.weight\n",
      "164 bert.encoder.layer.9.output.LayerNorm.bias\n",
      "165 bert.encoder.layer.10.attention.self.query.weight\n",
      "166 bert.encoder.layer.10.attention.self.query.bias\n",
      "167 bert.encoder.layer.10.attention.self.key.weight\n",
      "168 bert.encoder.layer.10.attention.self.key.bias\n",
      "169 bert.encoder.layer.10.attention.self.value.weight\n",
      "170 bert.encoder.layer.10.attention.self.value.bias\n",
      "171 bert.encoder.layer.10.attention.output.dense.weight\n",
      "172 bert.encoder.layer.10.attention.output.dense.bias\n",
      "173 bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "174 bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "175 bert.encoder.layer.10.intermediate.dense.weight\n",
      "176 bert.encoder.layer.10.intermediate.dense.bias\n",
      "177 bert.encoder.layer.10.output.dense.weight\n",
      "178 bert.encoder.layer.10.output.dense.bias\n",
      "179 bert.encoder.layer.10.output.LayerNorm.weight\n",
      "180 bert.encoder.layer.10.output.LayerNorm.bias\n",
      "181 bert.encoder.layer.11.attention.self.query.weight\n",
      "182 bert.encoder.layer.11.attention.self.query.bias\n",
      "183 bert.encoder.layer.11.attention.self.key.weight\n",
      "184 bert.encoder.layer.11.attention.self.key.bias\n",
      "185 bert.encoder.layer.11.attention.self.value.weight\n",
      "186 bert.encoder.layer.11.attention.self.value.bias\n",
      "187 bert.encoder.layer.11.attention.output.dense.weight\n",
      "188 bert.encoder.layer.11.attention.output.dense.bias\n",
      "189 bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "190 bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "191 bert.encoder.layer.11.intermediate.dense.weight\n",
      "192 bert.encoder.layer.11.intermediate.dense.bias\n",
      "193 bert.encoder.layer.11.output.dense.weight\n",
      "194 bert.encoder.layer.11.output.dense.bias\n",
      "195 bert.encoder.layer.11.output.LayerNorm.weight\n",
      "196 bert.encoder.layer.11.output.LayerNorm.bias\n",
      "197 bert.pooler.dense.weight\n",
      "198 bert.pooler.dense.bias\n",
      "199 dense.0.weight\n",
      "200 dense.0.bias\n",
      "201 classifier.2.weight\n",
      "202 classifier.2.bias\n"
     ]
    }
   ],
   "source": [
    "# 파라메타 번호 확인 하기\n",
    "i = 0\n",
    "for name, param in NLP_module.named_parameters():\n",
    "    \n",
    "    print(i,name)\n",
    "    i+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5614f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "for i, (name, param) in enumerate(NLP_module.named_parameters()):\n",
    "    \n",
    "    param.requires_grad = False\n",
    "    if i == 198:\n",
    "        print('end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d25ef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bert.embeddings.word_embeddings.weight', Parameter containing:\n",
      "tensor([[-0.0102, -0.0615, -0.0265,  ..., -0.0199, -0.0372, -0.0098],\n",
      "        [-0.0117, -0.0600, -0.0323,  ..., -0.0168, -0.0401, -0.0107],\n",
      "        [-0.0198, -0.0627, -0.0326,  ..., -0.0165, -0.0420, -0.0032],\n",
      "        ...,\n",
      "        [-0.0218, -0.0556, -0.0135,  ..., -0.0043, -0.0151, -0.0249],\n",
      "        [-0.0462, -0.0565, -0.0019,  ...,  0.0157, -0.0139, -0.0095],\n",
      "        [ 0.0015, -0.0821, -0.0160,  ..., -0.0081, -0.0475,  0.0753]],\n",
      "       device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "for p in NLP_module.named_parameters():\n",
    "    print(p)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8573ba31",
   "metadata": {},
   "source": [
    "# LanguageAndVisionConcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9d5cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageAndVisionConcat(nn.Module):    \n",
    "    def __init__(\n",
    "        self,\n",
    "        nlp_module,\n",
    "        vision_module,\n",
    "        num_classes,\n",
    "        language_feature_dim,\n",
    "        vision_feature_dim,\n",
    "        fusion_output_size,\n",
    "        dropout_p):\n",
    "        super(LanguageAndVisionConcat, self).__init__()\n",
    "        self.nlp_module = nlp_module\n",
    "        self.vision_module = vision_module\n",
    "        self.fusion = torch.nn.Linear(\n",
    "                        in_features=(language_feature_dim + vision_feature_dim), \n",
    "                        out_features=fusion_output_size,\n",
    "        )\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(dropout_p)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(\n",
    "            in_features=fusion_output_size, \n",
    "            out_features=num_classes\n",
    "        )\n",
    "        \n",
    "   \n",
    "    \n",
    "    def forward(self, text, text2 , image):\n",
    "        text_features = torch.nn.functional.relu(\n",
    "            self.nlp_module(text, text2)\n",
    "        )\n",
    "        image_features = torch.nn.functional.relu(\n",
    "            self.vision_module(image)\n",
    "        )\n",
    "        combined = torch.cat(\n",
    "            [text_features, image_features], dim=1\n",
    "        )\n",
    "        fused = self.dropout(\n",
    "            torch.nn.functional.relu(\n",
    "            self.fusion(combined)\n",
    "            ))\n",
    "        logits = self.fc(fused)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2290753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageAndVisionConcat(\n",
       "  (nlp_module): BertClassifier(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dense): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=500, bias=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vision_module): resnet_classifier(\n",
       "    (resnet50): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=500, bias=True)\n",
       "    )\n",
       "    (classifier): Sequential(\n",
       "      (0): ReLU()\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=500, out_features=37, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fusion): Linear(in_features=74, out_features=37, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=37, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LanguageAndVisionConcat(\n",
    "        nlp_module = NLP_module,\n",
    "        vision_module = vision_module,\n",
    "        num_classes = class_num,\n",
    "        language_feature_dim = 37,\n",
    "        vision_feature_dim = 37,\n",
    "        fusion_output_size = 37,\n",
    "        dropout_p = 0.2\n",
    ")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de46ee4",
   "metadata": {},
   "source": [
    "# concat model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e309a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# # Observe that all parameters are being optimized\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Create the optimizer\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                  lr=5e-5,    # Default learning rate\n",
    "                  eps=1e-8    # Default epsilon value\n",
    "                  )\n",
    "\n",
    "# # Total number of training steps\n",
    "# total_steps = len(vision_train) * 2\n",
    "\n",
    "# # Set up the learning rate scheduler\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "#                                             num_warmup_steps=0, # Default value\n",
    "#                                             num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "744c4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_train =  dataloaders['train']\n",
    "vision_val =  dataloaders['val']\n",
    "vision_test =  dataloaders['test']\n",
    "\n",
    "nlp_train = train_dataloader\n",
    "nlp_val = val_dataloader\n",
    "nlp_test = test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1bdd19b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 3.527  val loss: 3.326 Acc: 17.95 time_elapsed: 30 second\n",
      "[2] Train loss: 3.176  val loss: 2.952 Acc: 29.68 time_elapsed: 27 second\n",
      "[3] Train loss: 2.811  val loss: 2.552 Acc: 43.64 time_elapsed: 26 second\n",
      "[4] Train loss: 2.434  val loss: 2.138 Acc: 53.49 time_elapsed: 26 second\n",
      "[5] Train loss: 2.044  val loss: 1.730 Acc: 60.02 time_elapsed: 26 second\n",
      "[6] Train loss: 1.656  val loss: 1.338 Acc: 65.42 time_elapsed: 27 second\n",
      "[7] Train loss: 1.312  val loss: 1.005 Acc: 69.62 time_elapsed: 26 second\n",
      "[8] Train loss: 1.021  val loss: 0.739 Acc: 72.89 time_elapsed: 26 second\n",
      "[9] Train loss: 0.785  val loss: 0.546 Acc: 75.45 time_elapsed: 26 second\n",
      "[10] Train loss: 0.592  val loss: 0.400 Acc: 77.5 time_elapsed: 26 second\n",
      "[11] Train loss: 0.465  val loss: 0.313 Acc: 79.18 time_elapsed: 27 second\n",
      "[12] Train loss: 0.368  val loss: 0.253 Acc: 80.59 time_elapsed: 26 second\n",
      "[13] Train loss: 0.303  val loss: 0.205 Acc: 81.77 time_elapsed: 26 second\n",
      "[14] Train loss: 0.255  val loss: 0.178 Acc: 82.8 time_elapsed: 26 second\n",
      "[15] Train loss: 0.216  val loss: 0.156 Acc: 83.69 time_elapsed: 26 second\n",
      "[16] Train loss: 0.193  val loss: 0.140 Acc: 84.5 time_elapsed: 26 second\n",
      "[17] Train loss: 0.172  val loss: 0.129 Acc: 85.2 time_elapsed: 27 second\n",
      "[18] Train loss: 0.151  val loss: 0.121 Acc: 85.81 time_elapsed: 26 second\n",
      "[19] Train loss: 0.140  val loss: 0.112 Acc: 86.4 time_elapsed: 26 second\n",
      "[20] Train loss: 0.129  val loss: 0.106 Acc: 86.94 time_elapsed: 26 second\n",
      "[21] Train loss: 0.115  val loss: 0.102 Acc: 87.43 time_elapsed: 26 second\n",
      "[22] Train loss: 0.109  val loss: 0.097 Acc: 87.89 time_elapsed: 26 second\n",
      "[23] Train loss: 0.102  val loss: 0.094 Acc: 88.3 time_elapsed: 26 second\n",
      "[24] Train loss: 0.097  val loss: 0.091 Acc: 88.68 time_elapsed: 26 second\n",
      "[25] Train loss: 0.089  val loss: 0.089 Acc: 89.02 time_elapsed: 26 second\n",
      "[26] Train loss: 0.087  val loss: 0.086 Acc: 89.35 time_elapsed: 26 second\n",
      "[27] Train loss: 0.082  val loss: 0.084 Acc: 89.65 time_elapsed: 26 second\n",
      "[28] Train loss: 0.080  val loss: 0.082 Acc: 89.94 time_elapsed: 26 second\n",
      "[29] Train loss: 0.072  val loss: 0.081 Acc: 90.2 time_elapsed: 26 second\n",
      "[30] Train loss: 0.071  val loss: 0.080 Acc: 90.45 time_elapsed: 26 second\n",
      "[31] Train loss: 0.071  val loss: 0.078 Acc: 90.69 time_elapsed: 26 second\n",
      "[32] Train loss: 0.066  val loss: 0.077 Acc: 90.91 time_elapsed: 26 second\n",
      "[33] Train loss: 0.067  val loss: 0.077 Acc: 91.11 time_elapsed: 26 second\n",
      "[34] Train loss: 0.063  val loss: 0.076 Acc: 91.31 time_elapsed: 26 second\n",
      "[35] Train loss: 0.067  val loss: 0.076 Acc: 91.49 time_elapsed: 26 second\n",
      "[36] Train loss: 0.066  val loss: 0.074 Acc: 91.66 time_elapsed: 26 second\n",
      "[37] Train loss: 0.061  val loss: 0.075 Acc: 91.82 time_elapsed: 26 second\n",
      "[38] Train loss: 0.058  val loss: 0.074 Acc: 91.97 time_elapsed: 26 second\n",
      "[39] Train loss: 0.058  val loss: 0.072 Acc: 92.12 time_elapsed: 26 second\n",
      "[40] Train loss: 0.057  val loss: 0.073 Acc: 92.26 time_elapsed: 26 second\n",
      "[41] Train loss: 0.057  val loss: 0.073 Acc: 92.4 time_elapsed: 26 second\n",
      "[42] Train loss: 0.055  val loss: 0.072 Acc: 92.52 time_elapsed: 26 second\n",
      "[43] Train loss: 0.056  val loss: 0.071 Acc: 92.64 time_elapsed: 26 second\n",
      "[44] Train loss: 0.052  val loss: 0.071 Acc: 92.76 time_elapsed: 26 second\n",
      "[45] Train loss: 0.051  val loss: 0.071 Acc: 92.87 time_elapsed: 26 second\n",
      "[46] Train loss: 0.054  val loss: 0.072 Acc: 92.98 time_elapsed: 26 second\n",
      "[47] Train loss: 0.052  val loss: 0.072 Acc: 93.08 time_elapsed: 26 second\n",
      "[48] Train loss: 0.049  val loss: 0.071 Acc: 93.18 time_elapsed: 26 second\n",
      "[49] Train loss: 0.048  val loss: 0.071 Acc: 93.27 time_elapsed: 26 second\n",
      "[50] Train loss: 0.050  val loss: 0.070 Acc: 93.36 time_elapsed: 26 second\n",
      "[51] Train loss: 0.050  val loss: 0.070 Acc: 93.45 time_elapsed: 26 second\n",
      "[52] Train loss: 0.049  val loss: 0.071 Acc: 93.53 time_elapsed: 26 second\n",
      "[53] Train loss: 0.048  val loss: 0.070 Acc: 93.61 time_elapsed: 26 second\n",
      "[54] Train loss: 0.050  val loss: 0.070 Acc: 93.68 time_elapsed: 26 second\n",
      "[55] Train loss: 0.048  val loss: 0.069 Acc: 93.76 time_elapsed: 26 second\n",
      "[56] Train loss: 0.045  val loss: 0.070 Acc: 93.83 time_elapsed: 26 second\n",
      "[57] Train loss: 0.048  val loss: 0.069 Acc: 93.9 time_elapsed: 26 second\n",
      "[58] Train loss: 0.049  val loss: 0.069 Acc: 93.97 time_elapsed: 26 second\n",
      "[59] Train loss: 0.042  val loss: 0.069 Acc: 94.04 time_elapsed: 26 second\n",
      "[60] Train loss: 0.049  val loss: 0.072 Acc: 94.1 time_elapsed: 26 second\n",
      "[61] Train loss: 0.045  val loss: 0.069 Acc: 94.16 time_elapsed: 26 second\n",
      "[62] Train loss: 0.047  val loss: 0.069 Acc: 94.22 time_elapsed: 26 second\n",
      "[63] Train loss: 0.046  val loss: 0.071 Acc: 94.27 time_elapsed: 26 second\n",
      "[64] Train loss: 0.045  val loss: 0.070 Acc: 94.33 time_elapsed: 26 second\n",
      "[65] Train loss: 0.047  val loss: 0.068 Acc: 94.38 time_elapsed: 26 second\n",
      "[66] Train loss: 0.045  val loss: 0.069 Acc: 94.43 time_elapsed: 27 second\n",
      "[67] Train loss: 0.043  val loss: 0.068 Acc: 94.48 time_elapsed: 26 second\n",
      "[68] Train loss: 0.045  val loss: 0.068 Acc: 94.53 time_elapsed: 27 second\n",
      "[69] Train loss: 0.042  val loss: 0.068 Acc: 94.58 time_elapsed: 27 second\n",
      "[70] Train loss: 0.044  val loss: 0.068 Acc: 94.63 time_elapsed: 26 second\n",
      "[71] Train loss: 0.048  val loss: 0.068 Acc: 94.67 time_elapsed: 26 second\n",
      "[72] Train loss: 0.042  val loss: 0.068 Acc: 94.71 time_elapsed: 26 second\n",
      "[73] Train loss: 0.040  val loss: 0.069 Acc: 94.76 time_elapsed: 26 second\n",
      "[74] Train loss: 0.044  val loss: 0.068 Acc: 94.8 time_elapsed: 26 second\n",
      "[75] Train loss: 0.045  val loss: 0.068 Acc: 94.84 time_elapsed: 27 second\n",
      "[76] Train loss: 0.041  val loss: 0.068 Acc: 94.88 time_elapsed: 26 second\n",
      "[77] Train loss: 0.043  val loss: 0.069 Acc: 94.91 time_elapsed: 26 second\n",
      "[78] Train loss: 0.042  val loss: 0.068 Acc: 94.95 time_elapsed: 26 second\n",
      "[79] Train loss: 0.042  val loss: 0.070 Acc: 94.99 time_elapsed: 26 second\n",
      "[80] Train loss: 0.042  val loss: 0.069 Acc: 95.02 time_elapsed: 26 second\n",
      "[81] Train loss: 0.044  val loss: 0.070 Acc: 95.06 time_elapsed: 26 second\n",
      "[82] Train loss: 0.040  val loss: 0.069 Acc: 95.09 time_elapsed: 26 second\n",
      "[83] Train loss: 0.042  val loss: 0.067 Acc: 95.13 time_elapsed: 27 second\n",
      "[84] Train loss: 0.040  val loss: 0.070 Acc: 95.16 time_elapsed: 26 second\n",
      "[85] Train loss: 0.040  val loss: 0.071 Acc: 95.19 time_elapsed: 26 second\n",
      "[86] Train loss: 0.039  val loss: 0.068 Acc: 95.22 time_elapsed: 26 second\n",
      "[87] Train loss: 0.041  val loss: 0.070 Acc: 95.25 time_elapsed: 26 second\n",
      "[88] Train loss: 0.038  val loss: 0.069 Acc: 95.28 time_elapsed: 26 second\n",
      "[89] Train loss: 0.042  val loss: 0.070 Acc: 95.31 time_elapsed: 26 second\n",
      "[90] Train loss: 0.043  val loss: 0.069 Acc: 95.34 time_elapsed: 27 second\n",
      "[91] Train loss: 0.042  val loss: 0.069 Acc: 95.37 time_elapsed: 26 second\n",
      "[92] Train loss: 0.042  val loss: 0.069 Acc: 95.4 time_elapsed: 26 second\n",
      "[93] Train loss: 0.042  val loss: 0.070 Acc: 95.42 time_elapsed: 26 second\n",
      "[94] Train loss: 0.039  val loss: 0.069 Acc: 95.45 time_elapsed: 26 second\n",
      "[95] Train loss: 0.043  val loss: 0.069 Acc: 95.48 time_elapsed: 26 second\n",
      "[96] Train loss: 0.039  val loss: 0.069 Acc: 95.5 time_elapsed: 26 second\n",
      "[97] Train loss: 0.041  val loss: 0.069 Acc: 95.53 time_elapsed: 26 second\n",
      "[98] Train loss: 0.040  val loss: 0.069 Acc: 95.55 time_elapsed: 26 second\n",
      "[99] Train loss: 0.042  val loss: 0.070 Acc: 95.58 time_elapsed: 27 second\n",
      "[100] Train loss: 0.040  val loss: 0.070 Acc: 95.6 time_elapsed: 26 second\n",
      "[101] Train loss: 0.039  val loss: 0.069 Acc: 95.62 time_elapsed: 26 second\n",
      "[102] Train loss: 0.039  val loss: 0.069 Acc: 95.64 time_elapsed: 27 second\n",
      "[103] Train loss: 0.039  val loss: 0.068 Acc: 95.67 time_elapsed: 26 second\n",
      "[104] Train loss: 0.038  val loss: 0.068 Acc: 95.69 time_elapsed: 27 second\n",
      "[105] Train loss: 0.042  val loss: 0.069 Acc: 95.71 time_elapsed: 27 second\n",
      "[106] Train loss: 0.041  val loss: 0.071 Acc: 95.73 time_elapsed: 26 second\n",
      "[107] Train loss: 0.039  val loss: 0.069 Acc: 95.75 time_elapsed: 26 second\n",
      "[108] Train loss: 0.040  val loss: 0.068 Acc: 95.77 time_elapsed: 26 second\n",
      "[109] Train loss: 0.042  val loss: 0.070 Acc: 95.79 time_elapsed: 26 second\n",
      "[110] Train loss: 0.040  val loss: 0.071 Acc: 95.81 time_elapsed: 26 second\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111] Train loss: 0.036  val loss: 0.069 Acc: 95.83 time_elapsed: 26 second\n",
      "[112] Train loss: 0.041  val loss: 0.068 Acc: 95.84 time_elapsed: 26 second\n",
      "[113] Train loss: 0.039  val loss: 0.070 Acc: 95.86 time_elapsed: 26 second\n",
      "[114] Train loss: 0.039  val loss: 0.070 Acc: 95.88 time_elapsed: 26 second\n",
      "[115] Train loss: 0.041  val loss: 0.070 Acc: 95.9 time_elapsed: 26 second\n",
      "[116] Train loss: 0.041  val loss: 0.070 Acc: 95.91 time_elapsed: 27 second\n",
      "[117] Train loss: 0.038  val loss: 0.072 Acc: 95.93 time_elapsed: 26 second\n",
      "[118] Train loss: 0.034  val loss: 0.070 Acc: 95.95 time_elapsed: 26 second\n",
      "[119] Train loss: 0.038  val loss: 0.070 Acc: 95.96 time_elapsed: 26 second\n",
      "[120] Train loss: 0.039  val loss: 0.070 Acc: 95.98 time_elapsed: 26 second\n",
      "[121] Train loss: 0.038  val loss: 0.069 Acc: 96.0 time_elapsed: 26 second\n",
      "[122] Train loss: 0.038  val loss: 0.070 Acc: 96.01 time_elapsed: 26 second\n",
      "[123] Train loss: 0.041  val loss: 0.072 Acc: 96.03 time_elapsed: 26 second\n",
      "[124] Train loss: 0.038  val loss: 0.069 Acc: 96.04 time_elapsed: 26 second\n",
      "[125] Train loss: 0.041  val loss: 0.069 Acc: 96.06 time_elapsed: 26 second\n",
      "[126] Train loss: 0.034  val loss: 0.069 Acc: 96.07 time_elapsed: 26 second\n",
      "[127] Train loss: 0.039  val loss: 0.071 Acc: 96.09 time_elapsed: 26 second\n",
      "[128] Train loss: 0.038  val loss: 0.069 Acc: 96.1 time_elapsed: 26 second\n",
      "[129] Train loss: 0.039  val loss: 0.069 Acc: 96.12 time_elapsed: 26 second\n",
      "[130] Train loss: 0.036  val loss: 0.070 Acc: 96.13 time_elapsed: 26 second\n",
      "[131] Train loss: 0.036  val loss: 0.068 Acc: 96.14 time_elapsed: 26 second\n",
      "[132] Train loss: 0.037  val loss: 0.070 Acc: 96.16 time_elapsed: 26 second\n",
      "[133] Train loss: 0.038  val loss: 0.072 Acc: 96.17 time_elapsed: 26 second\n",
      "[134] Train loss: 0.039  val loss: 0.069 Acc: 96.18 time_elapsed: 27 second\n",
      "[135] Train loss: 0.037  val loss: 0.069 Acc: 96.19 time_elapsed: 26 second\n",
      "[136] Train loss: 0.034  val loss: 0.069 Acc: 96.21 time_elapsed: 27 second\n",
      "[137] Train loss: 0.039  val loss: 0.069 Acc: 96.22 time_elapsed: 26 second\n",
      "[138] Train loss: 0.034  val loss: 0.073 Acc: 96.23 time_elapsed: 26 second\n",
      "[139] Train loss: 0.038  val loss: 0.069 Acc: 96.24 time_elapsed: 27 second\n",
      "[140] Train loss: 0.041  val loss: 0.070 Acc: 96.25 time_elapsed: 27 second\n",
      "[141] Train loss: 0.038  val loss: 0.070 Acc: 96.27 time_elapsed: 27 second\n",
      "[142] Train loss: 0.035  val loss: 0.071 Acc: 96.28 time_elapsed: 26 second\n",
      "[143] Train loss: 0.038  val loss: 0.068 Acc: 96.29 time_elapsed: 27 second\n",
      "[144] Train loss: 0.038  val loss: 0.070 Acc: 96.3 time_elapsed: 27 second\n",
      "[145] Train loss: 0.036  val loss: 0.070 Acc: 96.31 time_elapsed: 27 second\n",
      "[146] Train loss: 0.036  val loss: 0.070 Acc: 96.33 time_elapsed: 27 second\n",
      "[147] Train loss: 0.035  val loss: 0.072 Acc: 96.34 time_elapsed: 27 second\n",
      "[148] Train loss: 0.038  val loss: 0.070 Acc: 96.35 time_elapsed: 27 second\n",
      "[149] Train loss: 0.039  val loss: 0.072 Acc: 96.36 time_elapsed: 27 second\n",
      "[150] Train loss: 0.037  val loss: 0.069 Acc: 96.37 time_elapsed: 27 second\n",
      "[151] Train loss: 0.037  val loss: 0.071 Acc: 96.38 time_elapsed: 27 second\n",
      "[152] Train loss: 0.040  val loss: 0.070 Acc: 96.39 time_elapsed: 26 second\n",
      "[153] Train loss: 0.036  val loss: 0.071 Acc: 96.4 time_elapsed: 26 second\n",
      "[154] Train loss: 0.036  val loss: 0.071 Acc: 96.41 time_elapsed: 27 second\n",
      "[155] Train loss: 0.035  val loss: 0.072 Acc: 96.41 time_elapsed: 27 second\n",
      "[156] Train loss: 0.034  val loss: 0.070 Acc: 96.42 time_elapsed: 27 second\n",
      "[157] Train loss: 0.037  val loss: 0.068 Acc: 96.43 time_elapsed: 26 second\n",
      "[158] Train loss: 0.036  val loss: 0.069 Acc: 96.44 time_elapsed: 27 second\n",
      "[159] Train loss: 0.037  val loss: 0.071 Acc: 96.45 time_elapsed: 26 second\n",
      "[160] Train loss: 0.035  val loss: 0.070 Acc: 96.46 time_elapsed: 27 second\n",
      "[161] Train loss: 0.035  val loss: 0.072 Acc: 96.47 time_elapsed: 26 second\n",
      "[162] Train loss: 0.033  val loss: 0.071 Acc: 96.48 time_elapsed: 27 second\n",
      "[163] Train loss: 0.036  val loss: 0.071 Acc: 96.49 time_elapsed: 27 second\n",
      "[164] Train loss: 0.037  val loss: 0.071 Acc: 96.49 time_elapsed: 26 second\n",
      "[165] Train loss: 0.035  val loss: 0.071 Acc: 96.5 time_elapsed: 26 second\n",
      "[166] Train loss: 0.035  val loss: 0.071 Acc: 96.51 time_elapsed: 26 second\n",
      "[167] Train loss: 0.034  val loss: 0.068 Acc: 96.52 time_elapsed: 27 second\n",
      "[168] Train loss: 0.036  val loss: 0.069 Acc: 96.53 time_elapsed: 27 second\n",
      "[169] Train loss: 0.035  val loss: 0.069 Acc: 96.54 time_elapsed: 27 second\n",
      "[170] Train loss: 0.033  val loss: 0.070 Acc: 96.54 time_elapsed: 27 second\n",
      "[171] Train loss: 0.033  val loss: 0.071 Acc: 96.55 time_elapsed: 27 second\n",
      "[172] Train loss: 0.037  val loss: 0.071 Acc: 96.56 time_elapsed: 27 second\n",
      "[173] Train loss: 0.033  val loss: 0.069 Acc: 96.57 time_elapsed: 27 second\n",
      "[174] Train loss: 0.040  val loss: 0.072 Acc: 96.58 time_elapsed: 27 second\n",
      "[175] Train loss: 0.035  val loss: 0.071 Acc: 96.58 time_elapsed: 26 second\n",
      "[176] Train loss: 0.033  val loss: 0.072 Acc: 96.59 time_elapsed: 27 second\n",
      "[177] Train loss: 0.037  val loss: 0.072 Acc: 96.6 time_elapsed: 27 second\n",
      "[178] Train loss: 0.035  val loss: 0.071 Acc: 96.6 time_elapsed: 27 second\n",
      "[179] Train loss: 0.038  val loss: 0.070 Acc: 96.61 time_elapsed: 27 second\n",
      "[180] Train loss: 0.033  val loss: 0.071 Acc: 96.62 time_elapsed: 27 second\n",
      "[181] Train loss: 0.031  val loss: 0.071 Acc: 96.63 time_elapsed: 27 second\n",
      "[182] Train loss: 0.036  val loss: 0.072 Acc: 96.64 time_elapsed: 27 second\n",
      "[183] Train loss: 0.035  val loss: 0.073 Acc: 96.64 time_elapsed: 26 second\n",
      "[184] Train loss: 0.038  val loss: 0.072 Acc: 96.65 time_elapsed: 26 second\n",
      "[185] Train loss: 0.033  val loss: 0.074 Acc: 96.65 time_elapsed: 26 second\n",
      "[186] Train loss: 0.033  val loss: 0.074 Acc: 96.66 time_elapsed: 26 second\n",
      "[187] Train loss: 0.037  val loss: 0.073 Acc: 96.67 time_elapsed: 27 second\n",
      "[188] Train loss: 0.039  val loss: 0.073 Acc: 96.68 time_elapsed: 26 second\n",
      "[189] Train loss: 0.037  val loss: 0.072 Acc: 96.68 time_elapsed: 26 second\n",
      "[190] Train loss: 0.038  val loss: 0.071 Acc: 96.69 time_elapsed: 26 second\n",
      "[191] Train loss: 0.035  val loss: 0.071 Acc: 96.69 time_elapsed: 26 second\n",
      "[192] Train loss: 0.036  val loss: 0.072 Acc: 96.7 time_elapsed: 26 second\n",
      "[193] Train loss: 0.035  val loss: 0.072 Acc: 96.71 time_elapsed: 26 second\n",
      "[194] Train loss: 0.034  val loss: 0.071 Acc: 96.71 time_elapsed: 26 second\n",
      "[195] Train loss: 0.035  val loss: 0.074 Acc: 96.72 time_elapsed: 26 second\n",
      "[196] Train loss: 0.033  val loss: 0.071 Acc: 96.73 time_elapsed: 26 second\n",
      "[197] Train loss: 0.037  val loss: 0.073 Acc: 96.73 time_elapsed: 26 second\n",
      "[198] Train loss: 0.034  val loss: 0.075 Acc: 96.74 time_elapsed: 27 second\n",
      "[199] Train loss: 0.035  val loss: 0.073 Acc: 96.74 time_elapsed: 26 second\n",
      "[200] Train loss: 0.033  val loss: 0.073 Acc: 96.75 time_elapsed: 27 second\n",
      "Accuracy of the network on the val images: 96 %\n",
      "Best epoch: 200 Best Acc: 96.75\n"
     ]
    }
   ],
   "source": [
    "PATH =\"C:/Users/ANDlab3/Desktop/VisionAndNLP/checkpoint_best3/\"\n",
    "\n",
    "train_loss = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n",
    "eval_loss = []\n",
    "correct = 0\n",
    "total = 0\n",
    "best_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "epoch = 200\n",
    "# log_interval = 100\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    time_epoch = time.time()\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_dataloader:\n",
    "        b_input_ids, b_attn_mask, b_labels, v_image, v_label = tuple(t.to(device) for t in data)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids, b_attn_mask, v_image)\n",
    "        loss = criterion(outputs, v_label) # 손실함수 계산\n",
    "        loss.backward() # 손실함수 기준으로 역전파 선언\n",
    "        \n",
    "        # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "         # Update parameters and the learning rate\n",
    "        optimizer.step() # 가중치 최적화\n",
    "  #         scheduler.step() \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    train_loss.append(running_loss / len(vision_train))   \n",
    "    \n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        eval_running_loss = 0.0\n",
    "        for data in val_dataloader:\n",
    "            b_input_ids, b_attn_mask, b_labels, v_image, v_label = tuple(t.to(device) for t in data)\n",
    "\n",
    "            outputs = model(b_input_ids, b_attn_mask, v_image) \n",
    "            val_loss = criterion(outputs, v_label) \n",
    "            eval_running_loss += val_loss.item()\n",
    "\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "\n",
    "            total += v_label.size(0)\n",
    "\n",
    "            correct += (pred == v_label).sum().item()\n",
    "            acc =  (100 * correct / total)\n",
    "    \n",
    "        eval_loss.append(eval_running_loss / len(vision_val)) \n",
    "        \n",
    "        time_elapsed = time.time() - time_epoch\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            torch.save(model.state_dict(), PATH+str(epoch+1)+'_best_model.pt')\n",
    "            best_epoch = epoch+1\n",
    "        \n",
    "        print('[%d] Train loss: %.3f' %(epoch + 1, running_loss / len(vision_train))\n",
    "     ,' val loss: %.3f' %(eval_running_loss / len(vision_val))\n",
    "     ,'Acc:', round(acc,2) ,'time_elapsed:', round(time_elapsed),'second')\n",
    "        \n",
    "print('Accuracy of the network on the val images: %d %%' % (100 * correct / total))\n",
    "print('Best epoch:', best_epoch, 'Best Acc:', round(best_acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b9fce81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(eval_loss)\n",
    "plt.legend(['train','validation'])\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b52bd",
   "metadata": {},
   "source": [
    "# 베스트 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595c18fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = model.to(device) # 모델 선언\n",
    "# best_model.load_state_dict(torch.load(PATH+str(best_epoch)+'_best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b20d341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the val data: 97.73 %\n"
     ]
    }
   ],
   "source": [
    "test_total = 0\n",
    "test_correct = 0\n",
    "\n",
    "true = []\n",
    "test_pred = []\n",
    "# nlp_true = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in val_dataloader:\n",
    "        b_input_ids, b_attn_mask, b_labels, v_image, v_label = tuple(t.to(device) for t in data)\n",
    "\n",
    "        outputs = model(b_input_ids, b_attn_mask, v_image) \n",
    "\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        \n",
    "#         test = torch.argmax(outputs, 1)\n",
    "        \n",
    "        test_total += v_label.size(0)\n",
    "        test_correct += (pred == v_label).sum().item()\n",
    "        \n",
    "        true += v_label.cpu().numpy().tolist()\n",
    "#         nlp_true += b_labels.cpu().numpy().tolist()\n",
    "        test_pred += pred.cpu().numpy().tolist()        \n",
    "\n",
    "print('Accuracy of the network on the val data:', round((100 * test_correct / test_total),2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09e1c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  recall  f1-score  support\n",
      "0                 1.000   0.920     0.958   25.000\n",
      "1                 1.000   1.000     1.000   25.000\n",
      "2                 0.962   1.000     0.980   25.000\n",
      "3                 1.000   1.000     1.000   25.000\n",
      "4                 1.000   1.000     1.000   25.000\n",
      "5                 0.955   0.840     0.894   25.000\n",
      "6                 1.000   0.960     0.980   25.000\n",
      "7                 1.000   0.960     0.980   25.000\n",
      "8                 1.000   1.000     1.000   25.000\n",
      "9                 1.000   1.000     1.000   25.000\n",
      "10                0.759   0.880     0.815   25.000\n",
      "11                1.000   1.000     1.000   25.000\n",
      "12                0.926   1.000     0.962   25.000\n",
      "13                0.893   1.000     0.943   25.000\n",
      "14                0.950   0.760     0.844   25.000\n",
      "15                1.000   1.000     1.000   25.000\n",
      "16                1.000   1.000     1.000   25.000\n",
      "17                0.962   1.000     0.980   25.000\n",
      "18                1.000   1.000     1.000   25.000\n",
      "19                1.000   1.000     1.000   25.000\n",
      "20                0.962   1.000     0.980   25.000\n",
      "21                0.962   1.000     0.980   25.000\n",
      "22                1.000   1.000     1.000   25.000\n",
      "23                1.000   1.000     1.000   25.000\n",
      "24                1.000   1.000     1.000   25.000\n",
      "25                1.000   1.000     1.000   25.000\n",
      "26                0.923   0.960     0.941   25.000\n",
      "27                1.000   1.000     1.000   25.000\n",
      "28                1.000   1.000     1.000   25.000\n",
      "29                1.000   1.000     1.000   25.000\n",
      "30                1.000   1.000     1.000   25.000\n",
      "31                1.000   0.920     0.958   25.000\n",
      "32                1.000   1.000     1.000   25.000\n",
      "33                1.000   1.000     1.000   25.000\n",
      "34                0.962   1.000     0.980   25.000\n",
      "35                1.000   0.960     0.980   25.000\n",
      "36                1.000   1.000     1.000   25.000\n",
      "accuracy          0.977   0.977     0.977    0.977\n",
      "macro avg         0.979   0.977     0.977  925.000\n",
      "weighted avg      0.979   0.977     0.977  925.000\n"
     ]
    }
   ],
   "source": [
    "# Classification Report 저장\n",
    "CL_REPORT_FILE = \"./cl_report.csv\"\n",
    "\n",
    "cl_report = classification_report(true, test_pred, output_dict = True)\n",
    "cl_report_df = pd.DataFrame(cl_report).transpose()\n",
    "cl_report_df = cl_report_df.round(3)\n",
    "# cl_report_df.to_csv(CL_REPORT_FILE)\n",
    "print(cl_report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00756cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
